# Chapter12 동시성 최적화
## 12.1 동시성
- 동시성이랑 여러 스레드를 **동시에 실행하는 성질**을 말한다.
- 동시성의 목표는 명령어 실행 수나 데이터 접근 횟수를 줄이는 것이 아니라 자원을 최대한 활용해 **전체 실행 시간**을 줄이는 것이다.
- 이벤트가 발생하거나 자원을 사용할 수 있을때까지 기다리는 동안 프로그램의 일부 작동을 진행하게 한다.
  - **자원을 더 많이 활용**할 수 있고 **성능이 향상**된다.

### 12.1.1 동시성 용어 살펴보기
- 컴퓨터 하드웨어, 운영체제, 함수 라이브러리 및 C++ 자체 기능으로 프로그램에 동시성을 제공할 수 있다.

#### 시분할
- **운영체제에 있는 스케줄러의 기능**이다.
- 운영체제는 시분할을 위해 현재 실행 중인 프로그램과 시스템 작업 목록을 유지하고 각 프로그램에 사용할 수 있는 시간을 할당한다.
- 프로그램이 이벤트나 자원을 기다릴 때마다, 운영체제의 실행 가능한 목록에서 프로그램이 제외되며 다른 프로그램이 프로세서를 사용할 수 있게 한다.

#### 가상화
- 일반적인 유형의 가상화는 **하이퍼바이저**라고 하는 경량 운영체제가 프로세서의 사용 가능 시간을 **게스트 가상 머신**에 할당한다.
  - 게스트 가상 머신은 하나 이상의 프로그램을 실행하는 운영체제인 **파일 시스템 이미지**와 **메모리 이미지**를 포함하고 있다.
- 하이퍼바이저가 게스트 가상 머신을 실행할 때 특정 프로세서 명령과 특정 메모리 영역에 접근하면 하이퍼바이저에 트랩이 발생해 하이퍼바이저가 `I/O`장치와 다른 하드웨어 자원을 흉내내도록 해준다.
- 가상화의 장점
  - 게스트 가상 머신은 실행 상태가 아닐 경우 디스크의 파일 형태로 존재하며 여러 컴퓨터의 호스트에서 체크 포인터 지정 및 저장, 불러오기 및 재시작, 복사 및 실행을 할 수 있다.
  - 자원이 충분히 있다면 동시에 여러 게스트 가상 머신을 실행할 수 있다.
  - 게스트 가상 머신은 호스트 컴퓨터의 자원일부를 사용하도록 구성할 수 있다.

#### 컨테이너화
- 컨테이너가 **파일 시스템 이미지**와 체크포인트된 프로그램 상태를 포함하는 **메모리 이미지**를 저장한다는 점에서 **가상화**와 비슷하다.
- 컨테이너 호스트가 운영체제라는 점이 다르다.
  - 하이퍼바이저로 `I/O` 및 시스템 자원을 흉내내는 대신 **직접 제공**할 수 있다.

#### 대칭적 멀티 프로세서
- 똑같은 기계 코드를 실행하고 동일한 물리 메모리에 접근하는 **여러 실행 단위가 포함된 컴퓨터**이다.
- 현대의 멀티 코어 프로세서는 대칭적 멀티 프로세서이다.
  - 실행 중인 프로그램과 시스템 테스크를 사용 가능한 실행 단위에서 실행할 수 있다.
- 대칭적 멀티 프로세서는 **하드웨어 동시성**으로 여러 제어 스레드를 실행한다.
  - 실행 단위가 `n`개 라면 계산 제약 프로그램의 총 실행 시간을 `1/n`으로 줄일 수 있다.

#### 동시 멀티 스레딩
- 어떤 프로세서는 각 하드웨어 코어가 레지스터 집합을 2개 이상 갖고 연관된 명령 스트림을 2개 이상 실행하도록 설계 되었다.
  - 하나의 스트림이 지연되면 다른 스트림의 명령들을 실행할 수 있다.
- 이런 기능이 있는 프로세서 코어는 코어가 2개 이상인 것처럼 작동하므로 4코어 프로세서는 하드웨어 스레드를 8개 호스팅 할 수 있다.

#### 다중 프로세스
- **각각 자체적으로 보호된 가상 메모리 공간**을 갖는 **동시적 실행 스트림**이다.
- 프로세스는 파이프, 큐, 네트워크 `I/O`, 공유되지 않은 다른 메커니즘을 사용해 통신한다.
- 프로세스는 운영체제 등이 제공하는 동기화 장치를 사용하거나 입력을 사용할 수 있을 때까지 막으며 동기화한다.
- 프로세스의 장점은 운영체제가 하나의 프로세스를 다른 프로세스들에서 **분리**한다는 것이다.
  - 하나의 프로세스에 문제가 발생해도 다른 프로세스는 할 수 있는 일은 없지만 살아있다.
- 프로세스의 단점은 가상 메모리 테이블, 다중 실행 단위 콘텍스트, 일시 중지된 모든 스레드의 콘텍스트등 **상태**를 너무 많이 갖고 있다는 것이다.

#### 분산 처리
- **서로 다른 프로세서에 작업을 분산**하는 것을 말한다.
  - 프로세서보다 느린 링크를 통해 분산한다.
- 분산 처리의 예
  - `TCP/IP` 링크를 통해 통신하는 클라우드 인스턴스 클러스터가 있다.
  - 단일 PC에서 드라이버를 디스크 드라이브와 네트워크 카드에서 실행 중인 프로세서에 오프로딩 하는 것이 있다.
- 일반적인 분산 처리 설정에서는 **파이프라인**이나 **프로세스 네트워크**를 통해 데이터를 전달한다.
- 각 프로세스는 입력을 변환하는 작업을 수행하며 변환된 데이터를 파이프라인의 다음 단계로 전달한다.
- 상대적으로 비중이 큰 프로세스를 효율적으로 실행할 수 있게 해준다.
- 프로세스가 메모리를 공유하거나 서로 동기화하지 않기 때문에 최대 속도로 실행한다.

#### 스레드
- **같은 메모리를 공유**하는 프로세스 내 **동시적 실행 스트림**을 말한다.
- 운영체제 등이 제공하는 동기화 장치를 사용해 동기화하고 공유 메모리를 사용해 통신한다.
- 프로세스에 비해 스레드는 자원을 더 적게 소비하고 생성 및 전환 속도가 빠르다.
- 메모리 공간을 공유한다.
  - 한 스레드가 잘못된 메모리 위치에 값을 쓰면 다른 스레드의 자료구조를 덮어써서 충돌이나 예기치 않은 작동이 발생할 수 있다.
- 공유 메모리에 접근하는 속도는 공유되지 않은 메모리에 접근하는 속도보다 느리다.
- 대부분의 운영체제는 운영체제에 종속적인 라이브러리로 스레드를 지원한다.

#### 태스크
- 별도의 스레드 콘텍스트에서 **비동기적으로 호출될 수 있는 실행단위**를 말한다.
  - 태스크 기반 동시성에서는 태스크와 스레드를 별도로 명시적으로 관리해 태스크를 실행할 스레드에 할당할 수 있도록 한다.
- 태스크 기반 동시성은 스레드 위에 구축되므로 스레드의 장점과 단점을 모두 갖는다.
- 활성 상태인 소프트웨어 스레드 수를 하드웨어 스레드 수와 일치시켜 스레드를 효율적으로 실행할 수 있다.
  - 프로그램은 실행할 태스크의 우선순위를 정하고 대기하게 만들 수 있다.

### 12.1.2 교차 실행
- 동시성 프로그램은 **적재**, **저장**, **분기**로 추상화될 수 있다.
  - 분기는 프로그래밍의 복잡성과 무관한 것처럼 거의 무시된다.
- 두 제어 스레드를 동시 실행하는 작동은 두 스레드가 **적재** 및 **저장**하는 간단한 작동에 대한 교차 실행으로 모델링할 수 있다.
  - 스레드 1과 스레드 2가 하나의 문장으로 구성되면 가능한 인터리빙은 12, 21이다.
  - 2개의 문장으로 구성되면 1122, 1212, 2112, 1221 등 여러개이다.
- **싱글 코어 프로세서**를 사용하던 시절에는 **운영체제의 시분할**을 사용해 동시성을 구현하였다.
  - 하나의 스레드가 다른 스레드에게 제어 권한을 부여하기 전에 많은 명령들을 실행하기 때문에 경쟁 상태가 발생하는 경우가 적었다.
- **멀티 코어 프로세서**는 각 문자의 교차 실행이 가능하기 때문에 **경쟁상태**가 자주 발생한다.

### 12.1.3 순차적 일관성
- 프로그램이 `C++`의 제어문 흐름에 마치 문장을 작성한 순서대로 실행하는 것처럼 작동하는것을 의미한다.
- 변수를 **사용**하는 문장을 옮길 때 해당 **변수를 갱신하는 문장 앞**으로 옮기지 않으면 프로그램은 순차적으로 일관성이 있다.
- 변수를 **갱신**하는 문장을 옮길 때 해당 **변수를 사용하는 문장 앞**으로 옮기지 않으면 프로그램은 순차적으로 일관성이 있다.

### 12.1.4 경쟁 상태
- 동시성은 **두 함수를 언제 동시에 실행**하는지 **어떤 변수를 공유**하는지를 알 수 있는 방법을 제공하지 않는 문제를 만든다.
- 경쟁 상태는 프로그램을 실행했을 때 어떤 교차 실행이 발생하는지에 따라 두 문장을 동시에 실행한 결과가 달라질 수 있는 상태를 말한다.
  - 스레드 1이 x = 0으로 구성되고 스레드 2가 문장 x = 100으로 구성되면 프로그램의 결과는 **두 스레드의 경쟁 상태**에 따라 달라진다.
- 프로그램의 결과나 **경쟁 상태를 포함**하는 모든 프로그램의 결과는 **비결정적**이다. 예측할 수 없다!
- `C++` 표준 메모리 모델은 프로그램이 경쟁 상태를 포함하지 않는다면 순차적으로 일관성이 있는것처럼 행동한다고 말한다.
  - 프로그램이 경쟁상태를 포함하고 있다면 순차적 일관성을 위반할 수 있다.
```cpp
// 스레드 1, 코어 1에서 실행
shared_result_x = 1;
shared_flag_y = 1;

// 스레드 2, 코어 2에서 실행
while (shared_flag_y != 1);
  /* shared_flag_y가 1로 설정될 때까지 busy waiting */
assert(shared_result_x == 1);
```
- 스레드 1에서 계산한 `shared_result_x` 값을 스레드 2에서 사용한다.
- 스레드 1에서 `shared_flag_y`의 값을 설정해 스레드 2에서 사용할 준비가 되었다고 알려준다.
- 컴파일러나 프로세서가 스레드 1에 있는 두 문장의 순서를 바꾸면 스레드 2는 `shared_flag_y`값을 확인한 뒤 `while`문을 빠져나간다.
  - 이전 `shared_result_x`값을 확인하기 때문에 `assert`문을 통과하지 못한다.
  - 각 스레드는 순차적으로 일관성이 있지만 두 스레드의 상호 작용은 **경쟁 상태**이다.

### 12.1.5 동기화
- 여러 스레드에 있는 **문장의 교차 실행 순서를 강제**하는 것이다.
  - 개발자가 멀티스레드 프로그램에서 **어떤 순서로 문장을 실행**하는지를 추론할 수 있게 해준다.
- 동기화를 하지 않으면 어떤 순서로 문장을 실행하는지 예측할 수 없으므로 **스레드 간의 작업을 조정하기 어려워진다.**
- **운영체제가 제공하는 동기화 장치**는 동시성 프로그램의 특정 교차 실행을 강제해 동기화를 하기 위한 프로그래밍 구성 요소이다.
  - 동기화 장치는 하나의 스레드가 다른 스레드를 기다리거나 **대기**하도록 만든다.
  - 동기화 장치는 특정 실행 순서를 적용함으로써 경쟁 상태를 방지한다.
- 다양한 동기화 장치가 제안되고 구현되었다.
  - 윈도우는 어떤 스레드를 대기할 수 있는 이벤트, 뮤텍스, 세마포어, 시그널등 다양한 동기화 장치를 갖고 있다.
  - 리눅스는 자체적으로 풍부한 별도의 동기화 장치들을 갖고 있다.

### 12.1.6 원자성
- 공유변수에 대한 연산이 미완료된 상태에서 다른 스레드가 갱신한 값을 볼 수 있는 스레드가 하나도 없다면 해당 연산은 **원자성**을 갖는다고 말한다.
- 값을 갱신하는 연산이 원자성을 갖지 않는다면, 두 스레드 코드의 교차 실행 중 일부는 하나의 스레드에서 공유 변수에 접근할 수 있게 된다.
  - 다른 스레드에서 값을 갱신하는 연산을 하는 중이기 때문에 미완료된 상태에서 값이 서로 다를 때 발생한다.
- **원자성**은 **바람직하지 않은 상호관계**가 발생할 수 없다는 일종의 약속이다.

#### 상호 배제에 의한 원자성
- 원자성은 **상호 배제**를 통해 제공된다.
- 공유 변수에 접근하려고 하는 각 스레드는 공유 변수에 접근하기 전에 **뮤텍스를 획득**해야 하고 연산이 끝나면 **뮤텍스를 해제**해야 한다.
  - 프로그램에서 **뮤텍스를 획득하고 해제**하는 코드 사이에 있는 부분을 **임계 구역**이라고 한다.
- 한 스레드가 뮤텍스를 획득했다면 다른 모든 스레드에서 뮤텍스를 획득하려고 시도할 경우 **대기 상태**가 된다.
  - 공유 데이터에 연산을 수행할 수 있는 스레드는 한 번에 하나뿐이다.
  - 이 상황을 **스레드가 뮤텍스를 잡고 있다**고 한다.
- 뮤텍스는 스레드들이 임계 구역에 차례대로 접근할 수 있도록 **직렬화**한다.
- **공유 변수를 적재 및 저장**하는 연산은 반드시 **임계 구역 내부**에서 수행해야 한다.
  - 임계구역에는 오직 **하나의 스레드만 접근**해야 한다.
  - 그렇지 않으면 경쟁상태가 발생해 예기치 않은 결과가 나오게 된다.
- 컴파일러와 프로세서는 적재 및 저장하는 연산을 모두 옮긴다.
  - **메모리 펜스**라고 하는 메커니즘은 공유 변수를 적재 및 저장하는 연산이 **임계 구역 바깥으로 빠져나가는것을 막는다.**
- **임계 구역 위에 있는 메모리 펜스**는 공유 변수를 적재하는 연산이 임계 구역 위로 빠져나가지 않도록 막아야 한다.
  - 이 메모리 펜스는 **시멘틱을 획득한다**라고 한다.
- **임계 구역 아래에 있는 메모리 펜스**는 공유 변수를 저장하는 연산이 임계 구역 아래로 빠져나가지 않도록 막아야 한다.
  - 이 메모리 펜스는 **시멘틱을 해제한다**라고 한다.
- 싱글 코어 프로세서에는 메모리 펜스가 필요하지 않다.
  - 컴파일러는 여러 함수를 호출하는 코드에서 적재 및 저장하는 연산의 위치를 바꾸지 않았다.
  - 운영체제가 스레드르 바꿀 때 메모리는 필연적으로 동기화 되었다.
- 멀티 코어 프로세서에서 동기화 장치나 락프리 자료구조를 구현할 경우 메모리 펜스에 관심을 가져야 한다.
  - 표준 라이브러리나 운영체제 네이티브 라이브러리에서 제공하는 동기화를 사용할 경우에는 메모리 펜스를 걱정할 필요가 없다.

#### 원자성을 보장하는 하드웨어 연산
- 오직 하나의 스레드만 뮤텍스를 붙잡을 수 있으므로 공유 변수에서의 연산은 동시에 실행할 수 없다.
  - 임계 구역이 더 많은 시간을 소비할수록 임계 구역이 동시 실행에서 벗어나는 시간이 더 길어진다.
  - 공유 변수에서 연산하는 스레드가 더 많을 수록 임계 구역이 동시 실행에서 벗어나는 시간이 더 길어진다.
- 스레드가 뮤텍스를 해제하면 대기 중이던 다른 스레드가 뮤텍스를 획득할 수 있다.
  - 뮤텍스는 **어떤 다른 스레드**가 뮤텍스를 획득하는지 보장하지 않는다. (보장하는 데 드는 비용이 크기 때문이다.)
  - 뮤텍스를 획득하기 위해 대기 중인 스레드가 많다면 어떤 스레드는 뮤텍스를 **영원히 획득하지 못할 수도 있다.**
  - 이 스레드에서 수행하는 연산은 앞으로 나아갈 수 없는데 이런 상태를 **기아 상태**라고 한다.
- 스레드가 앞으로 나아갈 수 없는 상황이 발생할 수 있다.
  - 스레드가 첫 번째 뮤텍스를 붙잡고 있는 상태에서 두 번째 뮤텍스가 필요하다.
  - 다른 스레드가 두 번째 뮤텍스를 붙잡고 있는 상태에서 첫 번째 뮤텍스가 필요하다.
  - 이런 상황을 **데드락**이라 부른다.
- 스레드에서 똑같은 뮤텍스에 **락을 두 번** 걸면 스스로 데드락에 빠질 수 있다.
- 스레드 간에 뮤텍스에 대한 **순환 의존 관계**가 생기면 데드락에 빠질 수 있다.
- 여러 뮤텍스를 획득하려는 프로그램에 **교착 회피 전략**이 있다고 하더라도 **데드락 프리**임을 보장할 방법은 없다.
- 하드웨어를 통해 **원자적으로 수행할 수 있는 연산**만 사용해 **스레드 안전 자료구조**를 구현할 수 있다.
  - 이러한 방법으로 작동하는 코드는 뮤텍스를 획득하기 위해 기다릴 필요가 없으므로 **락프리 프로그래밍**이라고 한다.
- 락프리 프로그래밍은 동시 스레드 수를 매우 많이 늘릴 수 있지만 만병통치약은 아니다.
  - 스레드가 수행하는 명령이 한개 뿐이더라도 원자적연산으로 직렬화 된다.

## 12.2 C++ 동시성 기능
### 12.2.1 스레드
- 헤더 파일 `<thread>`는 템플릿 클래스인 `std::thread`를 제공한다.
  - 프로그램은 이 클래스를 통해 스레드 객체를 만들 수 있다.
- `std::thread`의 생성자는 인수로 호출 가능한 객체를 취하고 새로운 소프트웨어 스레드의 콘텍스트에서 실행한다.
- `C++`은 가변 템플릿 인수 포워딩을 사용해 임의의 인수 목록을 갖는 함수를 호출한다.
- `std::thread`는 운영체제 스레드를 관리하는 `RAII` 클래스이다.
  - `std::thread`는 운영체제의 네이티브 스레드 핸들을 반환하는 멤버함수 `get`을 제공한다.

#### std::thread 예제

```cpp
void f1(int n)
{
    std::cout << "thread " << n << std::endl;
}

void thread_example()
{
  std::thread t1;                  // 스레드가 아닌 스레드 변수
  t1 = std::thread(f1, 1);         // 스레드 변수에 스레드 대입
  t1.join();                       // 스레드가 완료될 때까지 기다림 
  std::thread t2(f1, 2);
  std::thread t3(std::move(t2));
  std::thread t4([]() {return; }); // 람다 사용 가능
  t4.detach();
  t3.join();
}
```

- **이동 생성자**가 호출되면 `t3`은 `t2`에서 시작한 스레드를 실행하고 `t2`는 빈스레드가 된다.
- `t4`는 호출 가능한 객체에 람다를 사용할 수도 있다는 것을 보여준다.
- `join()`을 사용할 경우 현재 스레드는 조인된 스레드가 완료될 때까지 기다린다.
- 운영체제 스레드는 `detach` 처럼 `std::thread` 객체와 분리할 수도 있다.
- `std::thread`를 파괴하기 전에 `join()`과 `detach()`를 모두 호출하지 않으면 소멸자가 terminate()를 호출해 프로그램 전체가 중단된다.

### 12.2.2 프로미스와 퓨처
- `std::promise`와 `std::future`는 하나의 스레드에서 다른 스레드로 메시지를 보내고 받는다.
- 프로미스와 퓨처는 값을 **비동기**로 생성하고 예외를 던질 수 있다.
- `std::promise` 템플릿의 인스턴스는 스레드가 지정된 타입의 값이나 예외를 저장하는 공유 상태를 설정할 수 있게 해준다.
  - 값을 보내는 스레드는 값을 받는 스레드가 공유 상태를 읽을때까지 기다리지 않고 즉시 실행을 재개한다.
- 프로미스의 공유 상태는 값이나 예외가 설정될 때까지 준비 상태가 되지 않는다.
- 스레드는 퓨처를 통해 프로미스의 **고유 상태**에 **저장된 값이나 예외**를 받을 수 있다.
  - 스레드는 퓨처에서 결과값을 받을 때까지 실행을 대기할 수 있으므로 퓨처는 **동기화 장치의 역할**을 한다.
- 값을 받는 스레드는 값이나 예외를 설정하는 함수 호출로 해당 프로미스가 준비 상태가 될 때까지 퓨처의 멤버 함수 `get()`의 호출을 보류한다.
- 퓨처는 프로미스로부터 값을 생성하거나 대입 받을 때까지 유효하지 않다.
- 프로미스와 퓨처는 복사할 수 없다.
- 프로미스는 **값을 보내는 스레드**에서 만들어지며 퓨처는 **값을 받는 스레드**에서 만들어진다.
- 퓨처가 준비되면 계산이 완료되었다는 시그널을 보낸다.
  - 프로그램은 퓨처에서 대기할 수 있으므로 스레드 종료 시점에서 대기할 필요는 없다.

#### std::promise, std::future 예제
```cpp
void promise_future_example()
{
    auto meaning = [](std::promise<int>& prom)
    {
        prom.set_value(42);
    };

    std::promise<int> prom;
    std::thread(meaning, std::ref(prom)).detach();

    std::future<int> result = prom.get_future();
    std::cout << "the meaning of life: " << result.get() << "\n";
}
```

- 프로미스 prom은 스레드가 호출되기 전에 생성된다.
- 익명 스레드를 생성한다.
  - 스레드 인수는 호출 가능한 객체인 람다 **meaning**과 **meaning의 인수인 프로미스 prom**이다.
- `detach`를 호출하면 실행 중인 스레드가 파괴된 익명 스레드에서 분리된다.
- 운영체제는 `meaning`을 실행할 준비를 하고 프로그램은 퓨처 `result`를 만든다.
- 프로그램은 스레드가 `prom`의 공유 상태를 설정하기를 기다리며 `result.get()`에서 대기한다.
- 스레드는 `prom.set_value(42)`를 호출해 **공유 상태를 준비 상태**로 만들고 프로그램을 **해제**한다.
- 프로그램은 `the meaning of life: 42`를 출력하고 종료된다.

### 12.2.3 비동기 태스크
- 태스크 템플릿 클래스는 호출 가능한 객체를 `try` 블록으로 감싸고 **프로미스에 반환된 값이나 던져진 예외를 저장**한다.
- 태스크는 스레드에서 호출 가능한 객체를 비동기적으로 호출할 수 있게 한다.
- 호출 가능한 객체를 태스크로 패키징하는 함수 `async()`를 제공하며 재사용 가능한 스레드에서 이 함수를 호출한다.

#### packaged_task 예제
- `std::packaged_task`는 모든 호출 가능한 객체를 감싸서 비동기적으로 호출할 수 있도록 한다.
- `std::packaged_task`는 호출 가능한 객체며 `std::thread`의 인수로 사용할 수 있다.

```cpp
void promise_future_example_2()
{
    auto meaning = std::packaged_task<int(int)>([](int n) {return n; });
    auto result = meaning.get_future();
    auto t = std::thread(std::move(meaning), 42);

    std::cout << "the meaning of life: " << result.get() << "\n";
    t.join();
}
```

- `std::packaged_task` 타입인 `meaning`은 호출 가능한 객체와 `std::promise`를 모두 포함하고 있다.
- 스레드의 콘텍스트에서 호출되는 프로미스의 소멸자를 가져오는 문제를 해결한다.

#### async 예제
- `<async>` 라이브러리는 **태스크를 기반**으로 하는 기능을 제공한다.
- `std::async()`는 인수로 받은 호출 가능한 객체를 실행하고, 호출 가능한 객체는 새 스레드의 콘텍스트에서 실행될 수 있다.

```cpp
void promise_future_example_3()
{
  auto meaning = [](int n) {return n;};
  auto result = std::async(std::move(meaning), 42);
  std::cout << "the meaning of life: " << result.get() << "\n";
}
```
- `meaning`으로 정의된 람다와 람다의 인수는 `std::async()`로 전달된다.
- `async()`의 템플릿 매개변수를 결정하기 위해 **타입 추론**을 사용한다.
- `std::async()`는 `int` 타입의 결과나 예외를 가져갈 수 있는 퓨처를 반환하며 이 값은 `result`로 이동된다.
- `result.get()`을 호출하면 `std::async()`에 의해 호출된 스레드가 `int` 타입의 인수를 반환함으로써 프로미스에 값을 채울때까지 대기한다.
- 스레드 종료는 `std::async()`안에서 관리하는데 이는 스레드 풀에서 스레드를 유지할 수 있다.

### 12.2.4 뮤텍스
#### std::mutex
- 간단하고 효율적인 뮤텍스
- 윈도우에서 우선 `busy waiting`을 시도하고 뮤텍스를 빨리 획득할 수 없을 경우 운영체제 호출로 돌아간다.

#### std::recursive_mutex
- 중첩된 함수 호출처럼 뮤텍스를 이미 가진 스레드가 다시 획득할 수 있게 해주는 뮤텍스이다.
- 이 클래스는 뮤텍스를 획득한 횟수를 세야 하므로 효율성이 떨어질 수 있다.

#### std::recursive_timed_mutex
- `std::mutex`와 `std::recursive_mutex`를 합쳐놓은 뮤텍스이다.
- 다양한 기능을 지원하지만 비용이 크다.

#### std::shared_time_mutex
- 뮤텍스를 획득하기 위해 시도하는 시간을 지정하거나 지정하지 않을 수 있는 공유 뮤텍스이다.

#### std::shared_mutex
- 간단한 공유 뮤텍스
- `C++17`에 추가되었다.

### 12.2.5 락
- 락이라는 단어는 구조화된 방법으로 뮤텍스를 획득하고 해제하는 `RAI` 클래스를 말한다.
- 뮤텍스와 락을 혼동할 수 있는데 아래와 같이 구별하면 된다.
  - 뮤텍스를 획득한다는 것은 뮤텍스에 락을 거는 것이다.
  - 뮤텍스를 해제한다는 것은 뮤텍스에 걸린 락을 푸는 것이다.
- `C++`의 뮤텍스 멤버 함수인 `lock()`을 통해 **뮤텍스를 획득**할 수 있다.

#### std::lock_duard
- 간단한 `RAII` 락이다.
- 프로그램은 클래스를 생성하는 과정에서 락을 획득하기 위해 기다리며 `lock_guard`가 파괴될 때 락을 푼다.
- 이전 표준에서 `scope_guard`라는 이름으로 구현되었다.

#### std::unique_lock
- `RAII` 락, 지연 락, 시간을 지정하는 락, 뮤텍스의 소유권 전달, 조건 변수의 사용을 제공하는 **범용 뮤텍스 소유권 클래스**이다.
- `C++14`에서는 `<shared_mutex>` 헤더 파일에 공유 뮤텍스가 추가되었다.

#### std::shared_lock
- 공유(읽기/쓰기) 뮤텍스를 위한 뮤텍스 소유권 클래스이다.
- `std::unique_lock`의 모든 기능과 공유 뮤텍스의 제어 기능을 제공한다.

### 12.2.6 조건 변수
- 조건 변수는 프로그램이 모니터 개념을 구현할 수 있게 해주며 자바에서는 동기화 클래스라는 개념으로 사용하고 있다.
  - 모니터는 여러 스레드 간에 자료구조를 공유한다.
- 스레드가 성공적으로 모니터에 들어가면 **공유 자료구조**를 갱신할 수 있는 **뮤텍스**를 소유하게 된다.
- 스레드는 공유 자료구조를 갱신한 후 독점 접근을 포기하며 모니터를 떠날 수 있다.
- 특정 변화가 있을 때까지 독점 접근을 일시적으로 포기하며 조건 변수에 대기할 수도 있다.

#### std::condition_variable
- 가장 효율적인 조건 변수
- 뮤텍스에 락을 걸려면 `std::unique_lock`을 사용해야 한다.

#### std::condition_variable_any
- `BasicLockable` 락을 사용할 수 있는 조건 변수
- 멤버 함수 `lock()`과 `unlock()`을 제공하는 모든 락에서 사용할 수 있다.
- `std::condition_variable`보다 효율적이지 않을 수 있다.

#### condition_variable 예제
```cpp
void cv_example()
{
  std::mutex m;
  std::condition_variable cv;
  bool terminate = false;
  int shared_data = 0;
  int counter = 0;

  auto consumer = [&]() {
    std::unique_lock<std::mutex> lk(m);
    do {
      while (!(terminate || shared_data != 0))
      {
         cv.wait(lk);
      }
      if (terminate)
      {
        break;
      }
      std::cout << "consuming " << shared_data << std::endl;
      shared_data = 0;
      cv.notify_one();
    } while (true);
  };

  auto producer = [&]() {
    std::unique_lock<std::mutex> lk(m);
    for (counter = 1; true; ++counter)
    {
      cv.wait(lk, [&]() {return terminate || shared_data == 0; });
      if (terminate)
      {
        break;
      }
      shared_data = counter;
      std::cout << "producing " << shared_data << std::endl;
      cv.notify_one();
    }
  };

  auto p = std::thread(producer);
  auto c = std::thread(consumer);
  std::this_thread::sleep_for(std::chrono::milliseconds(1000));
  {
    std::lock_guard<std::mutex> l(m);
    terminate = true;
  }
  std::cout << "total items produced " << counter << std::endl;
  cv.notify_all();
  p.join();
  c.join();
  exit(0);
}
```
- 생산자는 정수 타입을 갖는 `shared_data`를 0이 아닌 값으로 설정해 생산한다.
- 소비자는 `shared_data`를 0으로 다시 설정해 소비한다.
- 메인 스레드가 깨어나면 뮤텍스`m`에 락을 걸어 모니터에 들어가 `terminate` 플래그를 설정한다.
  - 생산자 소비자 스레드 모두 종료된다.
- 메인 프로그램은 조건 변수에게 종료 상태가 변경되었다고 알리고 두 스레드를 조인한 뒤 종료한다.
- `consumer`는 뮤텍스`m`에 락을 걸어 모니터에 들어간다.
  - 소비자는 조건 변수 `cv`에서 대기하는 반복문이다.
  - 소비자는 `cv`에서 대기하지만 `consumer`는 모니터에 없다.
  - 뮤텍스`m`은 다시 사용가능하고 소비할 무언가가 생기면 `cv`에게 알린다.
  - 소비자가 깨어나고 뮤텍스에 다시 락을 건 뒤 `cv.wait()`로 반환해 개념적으로 모니터에 다시 들어가게 된다.

### 12.2.7 공유 변수에 대한 원자적 연산
- 표준 라이브러리의 헤더 파일 `<atomic>`은 멀티스레드 동기화 장치를 구축하기 위한 저수준 도구들을 제공한다.
- **메모리 펜스**와 **원자적 적재 및 저장**이다.

#### load()
- `std::atomic<T>`는 멤버 함수 `T load(memory_order)`를 제공한다.
- 이 함수는 원자적으로 T 객체를 `std::atomic<T>`밖으로 복사한다.

#### store()
- `std::atomic<T>`는 멤버 함수 `void store(T, memory_order)`를 제공한다.
- 이 함수는 원자적으로 T 객체를 `std::atomic<T>`안으로 복사한다.

#### is_lock_free()
- 이 타입에 정의된 모든 연산이 읽기/수정/쓰기하는 하나의 기계어처럼 상호 배제를 사용하지 않고 구현된 경우 `true`를 반환한다.

#### 메모리 펜스
- `std::atomic`의 멤버 함수 대부분은 연산 주위에 세울 메모리 펜스를 선택하는 `memory_order`라는 인수를 선택적으로 취한다.
  - 인수 `memory_order`에 값을 지정하지 않았다면 기본 값으로 `memory_order_acq_rel`이 지정된다.
  - 항상 안전한 전체 펜스를 제공하지만 비용이 비쌀 수 있다.
- 메모리 펜스는 **메인 메모리**를 여러 **하드웨어 스레드의 캐시와 동기화**한다.
- 하나의 스레드를 다른 스레드와 동기화하기 위해 두 스레드 모두 메모리 펜스를 실행한다.
- C++에서 사용할 수 있는 메모리 펜스는 아래와 같다.

1. memory_order_acquire
   - 다른 스레드가 수행한 **모든 작업을 획득**한다는 의미로 생각할 수 있다.
   - 다음 적재 연산을 현재 적재 연산이나 이전 적재 연산 앞으로 옮기지 못하게 한다.
   - 현재 프로세서와 메인 메모리 사이에서 진행 중인 저장 연산을 완료하기 위해 기다린다.
   - 기본값으로 지정되는 전체 펜스보다 비용이 저렴할 수 있다.

2. memory_order_release
   - 이 시점에 스레드에서 수행한 **모든 작업을 해제**한다는 의미로 생각할 수 있다.
   - 스레드에서 수행한 이전 적재 연산이나 저장 연산을 현재 저장 연산 앞으로 옮기지 못하게 한다.
   - 이 작동은 형재 스레드에서 진행 중인 저장 연산을 완료하기 위해 기다린다.

3. memory_order_acq_rel
   - 앞에 나온 두 가지 펜스를 결합해 **전체 펜스**를 만든다.

4. memory_order_consume
   - 잠재적으로 더 약하고 빠른 `memory_order_acquire`형태이다.
   - 데이터에 의존하는 다른 연산을 수행하기 전에 현재 적재 연산이 수행되기만 하면 된다.

5. memory_order_reloaxed
   - 모든 연산을 재배열 할 수 있다.

### 12.2.8 미래의 C++ 동시성 기능
#### 협력형 멀티 스레딩
- 둘 이상의 소프트웨어 스레드가 명시적 문장으로 두 스레드 사이에서 실행을 전달하므로 실제로는 한 번에 하나의 스레드만 실행된다.
- **코루틴**은 협력형 멀티스레딩의 한 예이다.
- 각 스레드는 활발하게 실행 중이지 않을 경우 콘텍스트를 유지할 수 있다.
- 한 번에 하나의 스레드만 실행하므로 변수는 공유되지 않는다. 따라서 상호배제는 필요하지 않다.

#### SIMD 명령
- `Single Instruction Multiple Data`의 약자로 **하나의 명령어로 여러 개의 값을 동시에 계산**하는 방법이다.
- `SIMD`를 지원하는 프로세서에서 특정 명령은 레지스터의 벡터에서 작동한다.
- 프로세서는 벡터의 각 레지스터에서 동시에 같은 작동을 수행하므로 스칼라 연산보다 오버헤드를 줄인다.