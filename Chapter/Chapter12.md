# Chapter12 동시성 최적화
## 12.1 동시성
- 동시성이랑 여러 스레드를 **동시에 실행하는 성질**을 말한다.
- 동시성의 목표는 명령어 실행 수나 데이터 접근 횟수를 줄이는 것이 아니라 자원을 최대한 활용해 **전체 실행 시간**을 줄이는 것이다.
- 이벤트가 발생하거나 자원을 사용할 수 있을때까지 기다리는 동안 프로그램의 일부 작동을 진행하게 한다.
  - **자원을 더 많이 활용**할 수 있고 **성능이 향상**된다.

### 12.1.1 동시성 용어 살펴보기
- 컴퓨터 하드웨어, 운영체제, 함수 라이브러리 및 C++ 자체 기능으로 프로그램에 동시성을 제공할 수 있다.

#### 시분할
- **운영체제에 있는 스케줄러의 기능**이다.
- 운영체제는 시분할을 위해 현재 실행 중인 프로그램과 시스템 작업 목록을 유지하고 각 프로그램에 사용할 수 있는 시간을 할당한다.
- 프로그램이 이벤트나 자원을 기다릴 때마다, 운영체제의 실행 가능한 목록에서 프로그램이 제외되며 다른 프로그램이 프로세서를 사용할 수 있게 한다.

#### 가상화
- 일반적인 유형의 가상화는 **하이퍼바이저**라고 하는 경량 운영체제가 프로세서의 사용 가능 시간을 **게스트 가상 머신**에 할당한다.
  - 게스트 가상 머신은 하나 이상의 프로그램을 실행하는 운영체제인 **파일 시스템 이미지**와 **메모리 이미지**를 포함하고 있다.
- 하이퍼바이저가 게스트 가상 머신을 실행할 때 특정 프로세서 명령과 특정 메모리 영역에 접근하면 하이퍼바이저에 트랩이 발생해 하이퍼바이저가 `I/O`장치와 다른 하드웨어 자원을 흉내내도록 해준다.
- 가상화의 장점
  - 게스트 가상 머신은 실행 상태가 아닐 경우 디스크의 파일 형태로 존재하며 여러 컴퓨터의 호스트에서 체크 포인터 지정 및 저장, 불러오기 및 재시작, 복사 및 실행을 할 수 있다.
  - 자원이 충분히 있다면 동시에 여러 게스트 가상 머신을 실행할 수 있다.
  - 게스트 가상 머신은 호스트 컴퓨터의 자원일부를 사용하도록 구성할 수 있다.

#### 컨테이너화
- 컨테이너가 **파일 시스템 이미지**와 체크포인트된 프로그램 상태를 포함하는 **메모리 이미지**를 저장한다는 점에서 **가상화**와 비슷하다.
- 컨테이너 호스트가 운영체제라는 점이 다르다.
  - 하이퍼바이저로 `I/O` 및 시스템 자원을 흉내내는 대신 **직접 제공**할 수 있다.

#### 대칭적 멀티 프로세서
- 똑같은 기계 코드를 실행하고 동일한 물리 메모리에 접근하는 **여러 실행 단위가 포함된 컴퓨터**이다.
- 현대의 멀티 코어 프로세서는 대칭적 멀티 프로세서이다.
  - 실행 중인 프로그램과 시스템 테스크를 사용 가능한 실행 단위에서 실행할 수 있다.
- 대칭적 멀티 프로세서는 **하드웨어 동시성**으로 여러 제어 스레드를 실행한다.
  - 실행 단위가 `n`개 라면 계산 제약 프로그램의 총 실행 시간을 `1/n`으로 줄일 수 있다.

#### 동시 멀티 스레딩
- 어떤 프로세서는 각 하드웨어 코어가 레지스터 집합을 2개 이상 갖고 연관된 명령 스트림을 2개 이상 실행하도록 설계 되었다.
  - 하나의 스트림이 지연되면 다른 스트림의 명령들을 실행할 수 있다.
- 이런 기능이 있는 프로세서 코어는 코어가 2개 이상인 것처럼 작동하므로 4코어 프로세서는 하드웨어 스레드를 8개 호스팅 할 수 있다.

#### 다중 프로세스
- **각각 자체적으로 보호된 가상 메모리 공간**을 갖는 **동시적 실행 스트림**이다.
- 프로세스는 파이프, 큐, 네트워크 `I/O`, 공유되지 않은 다른 메커니즘을 사용해 통신한다.
- 프로세스는 운영체제 등이 제공하는 동기화 장치를 사용하거나 입력을 사용할 수 있을 때까지 막으며 동기화한다.
- 프로세스의 장점은 운영체제가 하나의 프로세스를 다른 프로세스들에서 **분리**한다는 것이다.
  - 하나의 프로세스에 문제가 발생해도 다른 프로세스는 할 수 있는 일은 없지만 살아있다.
- 프로세스의 단점은 가상 메모리 테이블, 다중 실행 단위 콘텍스트, 일시 중지된 모든 스레드의 콘텍스트등 **상태**를 너무 많이 갖고 있다는 것이다.

#### 분산 처리
- **서로 다른 프로세서에 작업을 분산**하는 것을 말한다.
  - 프로세서보다 느린 링크를 통해 분산한다.
- 분산 처리의 예
  - `TCP/IP` 링크를 통해 통신하는 클라우드 인스턴스 클러스터가 있다.
  - 단일 PC에서 드라이버를 디스크 드라이브와 네트워크 카드에서 실행 중인 프로세서에 오프로딩 하는 것이 있다.
- 일반적인 분산 처리 설정에서는 **파이프라인**이나 **프로세스 네트워크**를 통해 데이터를 전달한다.
- 각 프로세스는 입력을 변환하는 작업을 수행하며 변환된 데이터를 파이프라인의 다음 단계로 전달한다.
- 상대적으로 비중이 큰 프로세스를 효율적으로 실행할 수 있게 해준다.
- 프로세스가 메모리를 공유하거나 서로 동기화하지 않기 때문에 최대 속도로 실행한다.

#### 스레드
- **같은 메모리를 공유**하는 프로세스 내 **동시적 실행 스트림**을 말한다.
- 운영체제 등이 제공하는 동기화 장치를 사용해 동기화하고 공유 메모리를 사용해 통신한다.
- 프로세스에 비해 스레드는 자원을 더 적게 소비하고 생성 및 전환 속도가 빠르다.
- 메모리 공간을 공유한다.
  - 한 스레드가 잘못된 메모리 위치에 값을 쓰면 다른 스레드의 자료구조를 덮어써서 충돌이나 예기치 않은 작동이 발생할 수 있다.
- 공유 메모리에 접근하는 속도는 공유되지 않은 메모리에 접근하는 속도보다 느리다.
- 대부분의 운영체제는 운영체제에 종속적인 라이브러리로 스레드를 지원한다.

#### 태스크
- 별도의 스레드 콘텍스트에서 **비동기적으로 호출될 수 있는 실행단위**를 말한다.
  - 태스크 기반 동시성에서는 태스크와 스레드를 별도로 명시적으로 관리해 태스크를 실행할 스레드에 할당할 수 있도록 한다.
- 태스크 기반 동시성은 스레드 위에 구축되므로 스레드의 장점과 단점을 모두 갖는다.
- 활성 상태인 소프트웨어 스레드 수를 하드웨어 스레드 수와 일치시켜 스레드를 효율적으로 실행할 수 있다.
  - 프로그램은 실행할 태스크의 우선순위를 정하고 대기하게 만들 수 있다.

### 12.1.2 교차 실행
- 동시성 프로그램은 **적재**, **저장**, **분기**로 추상화될 수 있다.
  - 분기는 프로그래밍의 복잡성과 무관한 것처럼 거의 무시된다.
- 두 제어 스레드를 동시 실행하는 작동은 두 스레드가 **적재** 및 **저장**하는 간단한 작동에 대한 교차 실행으로 모델링할 수 있다.
  - 스레드 1과 스레드 2가 하나의 문장으로 구성되면 가능한 인터리빙은 12, 21이다.
  - 2개의 문장으로 구성되면 1122, 1212, 2112, 1221 등 여러개이다.
- **싱글 코어 프로세서**를 사용하던 시절에는 **운영체제의 시분할**을 사용해 동시성을 구현하였다.
  - 하나의 스레드가 다른 스레드에게 제어 권한을 부여하기 전에 많은 명령들을 실행하기 때문에 경쟁 상태가 발생하는 경우가 적었다.
- **멀티 코어 프로세서**는 각 문자의 교차 실행이 가능하기 때문에 **경쟁상태**가 자주 발생한다.

### 12.1.3 순차적 일관성
- 프로그램이 `C++`의 제어문 흐름에 마치 문장을 작성한 순서대로 실행하는 것처럼 작동하는것을 의미한다.
- 변수를 **사용**하는 문장을 옮길 때 해당 **변수를 갱신하는 문장 앞**으로 옮기지 않으면 프로그램은 순차적으로 일관성이 있다.
- 변수를 **갱신**하는 문장을 옮길 때 해당 **변수를 사용하는 문장 앞**으로 옮기지 않으면 프로그램은 순차적으로 일관성이 있다.

### 12.1.4 경쟁 상태
- 동시성은 **두 함수를 언제 동시에 실행**하는지 **어떤 변수를 공유**하는지를 알 수 있는 방법을 제공하지 않는 문제를 만든다.
- 경쟁 상태는 프로그램을 실행했을 때 어떤 교차 실행이 발생하는지에 따라 두 문장을 동시에 실행한 결과가 달라질 수 있는 상태를 말한다.
  - 스레드 1이 x = 0으로 구성되고 스레드 2가 문장 x = 100으로 구성되면 프로그램의 결과는 **두 스레드의 경쟁 상태**에 따라 달라진다.
- 프로그램의 결과나 **경쟁 상태를 포함**하는 모든 프로그램의 결과는 **비결정적**이다. 예측할 수 없다!
- `C++` 표준 메모리 모델은 프로그램이 경쟁 상태를 포함하지 않는다면 순차적으로 일관성이 있는것처럼 행동한다고 말한다.
  - 프로그램이 경쟁상태를 포함하고 있다면 순차적 일관성을 위반할 수 있다.
```cpp
// 스레드 1, 코어 1에서 실행
shared_result_x = 1;
shared_flag_y = 1;

// 스레드 2, 코어 2에서 실행
while (shared_flag_y != 1);
  /* shared_flag_y가 1로 설정될 때까지 busy waiting */
assert(shared_result_x == 1);
```
- 스레드 1에서 계산한 `shared_result_x` 값을 스레드 2에서 사용한다.
- 스레드 1에서 `shared_flag_y`의 값을 설정해 스레드 2에서 사용할 준비가 되었다고 알려준다.
- 컴파일러나 프로세서가 스레드 1에 있는 두 문장의 순서를 바꾸면 스레드 2는 `shared_flag_y`값을 확인한 뒤 `while`문을 빠져나간다.
  - 이전 `shared_result_x`값을 확인하기 때문에 `assert`문을 통과하지 못한다.
  - 각 스레드는 순차적으로 일관성이 있지만 두 스레드의 상호 작용은 **경쟁 상태**이다.

### 12.1.5 동기화
- 여러 스레드에 있는 **문장의 교차 실행 순서를 강제**하는 것이다.
  - 개발자가 멀티스레드 프로그램에서 **어떤 순서로 문장을 실행**하는지를 추론할 수 있게 해준다.
- 동기화를 하지 않으면 어떤 순서로 문장을 실행하는지 예측할 수 없으므로 **스레드 간의 작업을 조정하기 어려워진다.**
- **운영체제가 제공하는 동기화 장치**는 동시성 프로그램의 특정 교차 실행을 강제해 동기화를 하기 위한 프로그래밍 구성 요소이다.
  - 동기화 장치는 하나의 스레드가 다른 스레드를 기다리거나 **대기**하도록 만든다.
  - 동기화 장치는 특정 실행 순서를 적용함으로써 경쟁 상태를 방지한다.
- 다양한 동기화 장치가 제안되고 구현되었다.
  - 윈도우는 어떤 스레드를 대기할 수 있는 이벤트, 뮤텍스, 세마포어, 시그널등 다양한 동기화 장치를 갖고 있다.
  - 리눅스는 자체적으로 풍부한 별도의 동기화 장치들을 갖고 있다.

### 12.1.6 원자성
- 공유변수에 대한 연산이 미완료된 상태에서 다른 스레드가 갱신한 값을 볼 수 있는 스레드가 하나도 없다면 해당 연산은 **원자성**을 갖는다고 말한다.
- 값을 갱신하는 연산이 원자성을 갖지 않는다면, 두 스레드 코드의 교차 실행 중 일부는 하나의 스레드에서 공유 변수에 접근할 수 있게 된다.
  - 다른 스레드에서 값을 갱신하는 연산을 하는 중이기 때문에 미완료된 상태에서 값이 서로 다를 때 발생한다.
- **원자성**은 **바람직하지 않은 상호관계**가 발생할 수 없다는 일종의 약속이다.

#### 상호 배제에 의한 원자성
- 원자성은 **상호 배제**를 통해 제공된다.
- 공유 변수에 접근하려고 하는 각 스레드는 공유 변수에 접근하기 전에 **뮤텍스를 획득**해야 하고 연산이 끝나면 **뮤텍스를 해제**해야 한다.
  - 프로그램에서 **뮤텍스를 획득하고 해제**하는 코드 사이에 있는 부분을 **임계 구역**이라고 한다.
- 한 스레드가 뮤텍스를 획득했다면 다른 모든 스레드에서 뮤텍스를 획득하려고 시도할 경우 **대기 상태**가 된다.
  - 공유 데이터에 연산을 수행할 수 있는 스레드는 한 번에 하나뿐이다.
  - 이 상황을 **스레드가 뮤텍스를 잡고 있다**고 한다.
- 뮤텍스는 스레드들이 임계 구역에 차례대로 접근할 수 있도록 **직렬화**한다.
- **공유 변수를 적재 및 저장**하는 연산은 반드시 **임계 구역 내부**에서 수행해야 한다.
  - 임계구역에는 오직 **하나의 스레드만 접근**해야 한다.
  - 그렇지 않으면 경쟁상태가 발생해 예기치 않은 결과가 나오게 된다.
- 컴파일러와 프로세서는 적재 및 저장하는 연산을 모두 옮긴다.
  - **메모리 펜스**라고 하는 메커니즘은 공유 변수를 적재 및 저장하는 연산이 **임계 구역 바깥으로 빠져나가는것을 막는다.**
- **임계 구역 위에 있는 메모리 펜스**는 공유 변수를 적재하는 연산이 임계 구역 위로 빠져나가지 않도록 막아야 한다.
  - 이 메모리 펜스는 **시멘틱을 획득한다**라고 한다.
- **임계 구역 아래에 있는 메모리 펜스**는 공유 변수를 저장하는 연산이 임계 구역 아래로 빠져나가지 않도록 막아야 한다.
  - 이 메모리 펜스는 **시멘틱을 해제한다**라고 한다.
- 싱글 코어 프로세서에는 메모리 펜스가 필요하지 않다.
  - 컴파일러는 여러 함수를 호출하는 코드에서 적재 및 저장하는 연산의 위치를 바꾸지 않았다.
  - 운영체제가 스레드르 바꿀 때 메모리는 필연적으로 동기화 되었다.
- 멀티 코어 프로세서에서 동기화 장치나 락프리 자료구조를 구현할 경우 메모리 펜스에 관심을 가져야 한다.
  - 표준 라이브러리나 운영체제 네이티브 라이브러리에서 제공하는 동기화를 사용할 경우에는 메모리 펜스를 걱정할 필요가 없다.

#### 원자성을 보장하는 하드웨어 연산
- 오직 하나의 스레드만 뮤텍스를 붙잡을 수 있으므로 공유 변수에서의 연산은 동시에 실행할 수 없다.
  - 임계 구역이 더 많은 시간을 소비할수록 임계 구역이 동시 실행에서 벗어나는 시간이 더 길어진다.
  - 공유 변수에서 연산하는 스레드가 더 많을 수록 임계 구역이 동시 실행에서 벗어나는 시간이 더 길어진다.
- 스레드가 뮤텍스를 해제하면 대기 중이던 다른 스레드가 뮤텍스를 획득할 수 있다.
  - 뮤텍스는 **어떤 다른 스레드**가 뮤텍스를 획득하는지 보장하지 않는다. (보장하는 데 드는 비용이 크기 때문이다.)
  - 뮤텍스를 획득하기 위해 대기 중인 스레드가 많다면 어떤 스레드는 뮤텍스를 **영원히 획득하지 못할 수도 있다.**
  - 이 스레드에서 수행하는 연산은 앞으로 나아갈 수 없는데 이런 상태를 **기아 상태**라고 한다.
- 스레드가 앞으로 나아갈 수 없는 상황이 발생할 수 있다.
  - 스레드가 첫 번째 뮤텍스를 붙잡고 있는 상태에서 두 번째 뮤텍스가 필요하다.
  - 다른 스레드가 두 번째 뮤텍스를 붙잡고 있는 상태에서 첫 번째 뮤텍스가 필요하다.
  - 이런 상황을 **데드락**이라 부른다.
- 스레드에서 똑같은 뮤텍스에 **락을 두 번** 걸면 스스로 데드락에 빠질 수 있다.
- 스레드 간에 뮤텍스에 대한 **순환 의존 관계**가 생기면 데드락에 빠질 수 있다.
- 여러 뮤텍스를 획득하려는 프로그램에 **교착 회피 전략**이 있다고 하더라도 **데드락 프리**임을 보장할 방법은 없다.
- 하드웨어를 통해 **원자적으로 수행할 수 있는 연산**만 사용해 **스레드 안전 자료구조**를 구현할 수 있다.
  - 이러한 방법으로 작동하는 코드는 뮤텍스를 획득하기 위해 기다릴 필요가 없으므로 **락프리 프로그래밍**이라고 한다.
- 락프리 프로그래밍은 동시 스레드 수를 매우 많이 늘릴 수 있지만 만병통치약은 아니다.
  - 스레드가 수행하는 명령이 한개 뿐이더라도 원자적연산으로 직렬화 된다.