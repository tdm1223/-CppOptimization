# Chapter12 동시성 최적화
## 12.1 동시성
- 동시성이랑 여러 스레드를 **동시에 실행하는 성질**을 말한다.
- 동시성의 목표는 명령어 실행 수나 데이터 접근 횟수를 줄이는 것이 아니라 자원을 최대한 활용해 **전체 실행 시간**을 줄이는 것이다.
- 이벤트가 발생하거나 자원을 사용할 수 있을때까지 기다리는 동안 프로그램의 일부 작동을 진행하게 한다.
  - **자원을 더 많이 활용**할 수 있고 **성능이 향상**된다.

### 12.1.1 동시성 용어 살펴보기
- 컴퓨터 하드웨어, 운영체제, 함수 라이브러리 및 C++ 자체 기능으로 프로그램에 동시성을 제공할 수 있다.

#### 시분할
- **운영체제에 있는 스케줄러의 기능**이다.
- 운영체제는 시분할을 위해 현재 실행 중인 프로그램과 시스템 작업 목록을 유지하고 각 프로그램에 사용할 수 있는 시간을 할당한다.
- 프로그램이 이벤트나 자원을 기다릴 때마다, 운영체제의 실행 가능한 목록에서 프로그램이 제외되며 다른 프로그램이 프로세서를 사용할 수 있게 한다.

#### 가상화
- 일반적인 유형의 가상화는 **하이퍼바이저**라고 하는 경량 운영체제가 프로세서의 사용 가능 시간을 **게스트 가상 머신**에 할당한다.
  - 게스트 가상 머신은 하나 이상의 프로그램을 실행하는 운영체제인 **파일 시스템 이미지**와 **메모리 이미지**를 포함하고 있다.
- 하이퍼바이저가 게스트 가상 머신을 실행할 때 특정 프로세서 명령과 특정 메모리 영역에 접근하면 하이퍼바이저에 트랩이 발생해 하이퍼바이저가 `I/O`장치와 다른 하드웨어 자원을 흉내내도록 해준다.
- 가상화의 장점
  - 게스트 가상 머신은 실행 상태가 아닐 경우 디스크의 파일 형태로 존재하며 여러 컴퓨터의 호스트에서 체크 포인터 지정 및 저장, 불러오기 및 재시작, 복사 및 실행을 할 수 있다.
  - 자원이 충분히 있다면 동시에 여러 게스트 가상 머신을 실행할 수 있다.
  - 게스트 가상 머신은 호스트 컴퓨터의 자원일부를 사용하도록 구성할 수 있다.

#### 컨테이너화
- 컨테이너가 **파일 시스템 이미지**와 체크포인트된 프로그램 상태를 포함하는 **메모리 이미지**를 저장한다는 점에서 **가상화**와 비슷하다.
- 컨테이너 호스트가 운영체제라는 점이 다르다.
  - 하이퍼바이저로 `I/O` 및 시스템 자원을 흉내내는 대신 **직접 제공**할 수 있다.

#### 대칭적 멀티 프로세서
- 똑같은 기계 코드를 실행하고 동일한 물리 메모리에 접근하는 **여러 실행 단위가 포함된 컴퓨터**이다.
- 현대의 멀티 코어 프로세서는 대칭적 멀티 프로세서이다.
  - 실행 중인 프로그램과 시스템 테스크를 사용 가능한 실행 단위에서 실행할 수 있다.
- 대칭적 멀티 프로세서는 **하드웨어 동시성**으로 여러 제어 스레드를 실행한다.
  - 실행 단위가 `n`개 라면 계산 제약 프로그램의 총 실행 시간을 `1/n`으로 줄일 수 있다.

#### 동시 멀티 스레딩
- 어떤 프로세서는 각 하드웨어 코어가 레지스터 집합을 2개 이상 갖고 연관된 명령 스트림을 2개 이상 실행하도록 설계 되었다.
  - 하나의 스트림이 지연되면 다른 스트림의 명령들을 실행할 수 있다.
- 이런 기능이 있는 프로세서 코어는 코어가 2개 이상인 것처럼 작동하므로 4코어 프로세서는 하드웨어 스레드를 8개 호스팅 할 수 있다.

#### 다중 프로세스
- **각각 자체적으로 보호된 가상 메모리 공간**을 갖는 **동시적 실행 스트림**이다.
- 프로세스는 파이프, 큐, 네트워크 `I/O`, 공유되지 않은 다른 메커니즘을 사용해 통신한다.
- 프로세스는 운영체제 등이 제공하는 동기화 장치를 사용하거나 입력을 사용할 수 있을 때까지 막으며 동기화한다.
- 프로세스의 장점은 운영체제가 하나의 프로세스를 다른 프로세스들에서 **분리**한다는 것이다.
  - 하나의 프로세스에 문제가 발생해도 다른 프로세스는 할 수 있는 일은 없지만 살아있다.
- 프로세스의 단점은 가상 메모리 테이블, 다중 실행 단위 콘텍스트, 일시 중지된 모든 스레드의 콘텍스트등 **상태**를 너무 많이 갖고 있다는 것이다.

#### 분산 처리
- **서로 다른 프로세서에 작업을 분산**하는 것을 말한다.
  - 프로세서보다 느린 링크를 통해 분산한다.
- 분산 처리의 예
  - `TCP/IP` 링크를 통해 통신하는 클라우드 인스턴스 클러스터가 있다.
  - 단일 PC에서 드라이버를 디스크 드라이브와 네트워크 카드에서 실행 중인 프로세서에 오프로딩 하는 것이 있다.
- 일반적인 분산 처리 설정에서는 **파이프라인**이나 **프로세스 네트워크**를 통해 데이터를 전달한다.
- 각 프로세스는 입력을 변환하는 작업을 수행하며 변환된 데이터를 파이프라인의 다음 단계로 전달한다.
- 상대적으로 비중이 큰 프로세스를 효율적으로 실행할 수 있게 해준다.
- 프로세스가 메모리를 공유하거나 서로 동기화하지 않기 때문에 최대 속도로 실행한다.

#### 스레드
- **같은 메모리를 공유**하는 프로세스 내 **동시적 실행 스트림**을 말한다.
- 운영체제 등이 제공하는 동기화 장치를 사용해 동기화하고 공유 메모리를 사용해 통신한다.
- 프로세스에 비해 스레드는 자원을 더 적게 소비하고 생성 및 전환 속도가 빠르다.
- 메모리 공간을 공유한다.
  - 한 스레드가 잘못된 메모리 위치에 값을 쓰면 다른 스레드의 자료구조를 덮어써서 충돌이나 예기치 않은 작동이 발생할 수 있다.
- 공유 메모리에 접근하는 속도는 공유되지 않은 메모리에 접근하는 속도보다 느리다.
- 대부분의 운영체제는 운영체제에 종속적인 라이브러리로 스레드를 지원한다.

#### 태스크
- 별도의 스레드 콘텍스트에서 **비동기적으로 호출될 수 있는 실행단위**를 말한다.
  - 태스크 기반 동시성에서는 태스크와 스레드를 별도로 명시적으로 관리해 태스크를 실행할 스레드에 할당할 수 있도록 한다.
- 태스크 기반 동시성은 스레드 위에 구축되므로 스레드의 장점과 단점을 모두 갖는다.
- 활성 상태인 소프트웨어 스레드 수를 하드웨어 스레드 수와 일치시켜 스레드를 효율적으로 실행할 수 있다.
  - 프로그램은 실행할 태스크의 우선순위를 정하고 대기하게 만들 수 있다.

### 12.1.2 교차 실행
- 동시성 프로그램은 **적재**, **저장**, **분기**로 추상화될 수 있다.
  - 분기는 프로그래밍의 복잡성과 무관한 것처럼 거의 무시된다.
- 두 제어 스레드를 동시 실행하는 작동은 두 스레드가 **적재** 및 **저장**하는 간단한 작동에 대한 교차 실행으로 모델링할 수 있다.
  - 스레드 1과 스레드 2가 하나의 문장으로 구성되면 가능한 인터리빙은 12, 21이다.
  - 2개의 문장으로 구성되면 1122, 1212, 2112, 1221 등 여러개이다.
- **싱글 코어 프로세서**를 사용하던 시절에는 **운영체제의 시분할**을 사용해 동시성을 구현하였다.
  - 하나의 스레드가 다른 스레드에게 제어 권한을 부여하기 전에 많은 명령들을 실행하기 때문에 경쟁 상태가 발생하는 경우가 적었다.
- **멀티 코어 프로세서**는 각 문자의 교차 실행이 가능하기 때문에 **경쟁상태**가 자주 발생한다.

### 12.1.3 순차적 일관성
- 프로그램이 `C++`의 제어문 흐름에 마치 문장을 작성한 순서대로 실행하는 것처럼 작동하는것을 의미한다.
- 변수를 **사용**하는 문장을 옮길 때 해당 **변수를 갱신하는 문장 앞**으로 옮기지 않으면 프로그램은 순차적으로 일관성이 있다.
- 변수를 **갱신**하는 문장을 옮길 때 해당 **변수를 사용하는 문장 앞**으로 옮기지 않으면 프로그램은 순차적으로 일관성이 있다.

### 12.1.4 경쟁 상태
- 동시성은 **두 함수를 언제 동시에 실행**하는지 **어떤 변수를 공유**하는지를 알 수 있는 방법을 제공하지 않는 문제를 만든다.
- 경쟁 상태는 프로그램을 실행했을 때 어떤 교차 실행이 발생하는지에 따라 두 문장을 동시에 실행한 결과가 달라질 수 있는 상태를 말한다.
  - 스레드 1이 x = 0으로 구성되고 스레드 2가 문장 x = 100으로 구성되면 프로그램의 결과는 **두 스레드의 경쟁 상태**에 따라 달라진다.
- 프로그램의 결과나 **경쟁 상태를 포함**하는 모든 프로그램의 결과는 **비결정적**이다. 예측할 수 없다!
- `C++` 표준 메모리 모델은 프로그램이 경쟁 상태를 포함하지 않는다면 순차적으로 일관성이 있는것처럼 행동한다고 말한다.
  - 프로그램이 경쟁상태를 포함하고 있다면 순차적 일관성을 위반할 수 있다.
```cpp
// 스레드 1, 코어 1에서 실행
shared_result_x = 1;
shared_flag_y = 1;

// 스레드 2, 코어 2에서 실행
while (shared_flag_y != 1);
  /* shared_flag_y가 1로 설정될 때까지 busy waiting */
assert(shared_result_x == 1);
```
- 스레드 1에서 계산한 `shared_result_x` 값을 스레드 2에서 사용한다.
- 스레드 1에서 `shared_flag_y`의 값을 설정해 스레드 2에서 사용할 준비가 되었다고 알려준다.
- 컴파일러나 프로세서가 스레드 1에 있는 두 문장의 순서를 바꾸면 스레드 2는 `shared_flag_y`값을 확인한 뒤 `while`문을 빠져나간다.
  - 이전 `shared_result_x`값을 확인하기 때문에 `assert`문을 통과하지 못한다.
  - 각 스레드는 순차적으로 일관성이 있지만 두 스레드의 상호 작용은 **경쟁 상태**이다.

### 12.1.5 동기화
- 여러 스레드에 있는 **문장의 교차 실행 순서를 강제**하는 것이다.
  - 개발자가 멀티스레드 프로그램에서 **어떤 순서로 문장을 실행**하는지를 추론할 수 있게 해준다.
- 동기화를 하지 않으면 어떤 순서로 문장을 실행하는지 예측할 수 없으므로 **스레드 간의 작업을 조정하기 어려워진다.**
- **운영체제가 제공하는 동기화 장치**는 동시성 프로그램의 특정 교차 실행을 강제해 동기화를 하기 위한 프로그래밍 구성 요소이다.
  - 동기화 장치는 하나의 스레드가 다른 스레드를 기다리거나 **대기**하도록 만든다.
  - 동기화 장치는 특정 실행 순서를 적용함으로써 경쟁 상태를 방지한다.
- 다양한 동기화 장치가 제안되고 구현되었다.
  - 윈도우는 어떤 스레드를 대기할 수 있는 이벤트, 뮤텍스, 세마포어, 시그널등 다양한 동기화 장치를 갖고 있다.
  - 리눅스는 자체적으로 풍부한 별도의 동기화 장치들을 갖고 있다.

### 12.1.6 원자성
- 공유변수에 대한 연산이 미완료된 상태에서 다른 스레드가 갱신한 값을 볼 수 있는 스레드가 하나도 없다면 해당 연산은 **원자성**을 갖는다고 말한다.
- 값을 갱신하는 연산이 원자성을 갖지 않는다면, 두 스레드 코드의 교차 실행 중 일부는 하나의 스레드에서 공유 변수에 접근할 수 있게 된다.
  - 다른 스레드에서 값을 갱신하는 연산을 하는 중이기 때문에 미완료된 상태에서 값이 서로 다를 때 발생한다.
- **원자성**은 **바람직하지 않은 상호관계**가 발생할 수 없다는 일종의 약속이다.

#### 상호 배제에 의한 원자성
- 원자성은 **상호 배제**를 통해 제공된다.
- 공유 변수에 접근하려고 하는 각 스레드는 공유 변수에 접근하기 전에 **뮤텍스를 획득**해야 하고 연산이 끝나면 **뮤텍스를 해제**해야 한다.
  - 프로그램에서 **뮤텍스를 획득하고 해제**하는 코드 사이에 있는 부분을 **임계 구역**이라고 한다.
- 한 스레드가 뮤텍스를 획득했다면 다른 모든 스레드에서 뮤텍스를 획득하려고 시도할 경우 **대기 상태**가 된다.
  - 공유 데이터에 연산을 수행할 수 있는 스레드는 한 번에 하나뿐이다.
  - 이 상황을 **스레드가 뮤텍스를 잡고 있다**고 한다.
- 뮤텍스는 스레드들이 임계 구역에 차례대로 접근할 수 있도록 **직렬화**한다.
- **공유 변수를 적재 및 저장**하는 연산은 반드시 **임계 구역 내부**에서 수행해야 한다.
  - 임계구역에는 오직 **하나의 스레드만 접근**해야 한다.
  - 그렇지 않으면 경쟁상태가 발생해 예기치 않은 결과가 나오게 된다.
- 컴파일러와 프로세서는 적재 및 저장하는 연산을 모두 옮긴다.
  - **메모리 펜스**라고 하는 메커니즘은 공유 변수를 적재 및 저장하는 연산이 **임계 구역 바깥으로 빠져나가는것을 막는다.**
- **임계 구역 위에 있는 메모리 펜스**는 공유 변수를 적재하는 연산이 임계 구역 위로 빠져나가지 않도록 막아야 한다.
  - 이 메모리 펜스는 **시멘틱을 획득한다**라고 한다.
- **임계 구역 아래에 있는 메모리 펜스**는 공유 변수를 저장하는 연산이 임계 구역 아래로 빠져나가지 않도록 막아야 한다.
  - 이 메모리 펜스는 **시멘틱을 해제한다**라고 한다.
- 싱글 코어 프로세서에는 메모리 펜스가 필요하지 않다.
  - 컴파일러는 여러 함수를 호출하는 코드에서 적재 및 저장하는 연산의 위치를 바꾸지 않았다.
  - 운영체제가 스레드르 바꿀 때 메모리는 필연적으로 동기화 되었다.
- 멀티 코어 프로세서에서 동기화 장치나 락프리 자료구조를 구현할 경우 메모리 펜스에 관심을 가져야 한다.
  - 표준 라이브러리나 운영체제 네이티브 라이브러리에서 제공하는 동기화를 사용할 경우에는 메모리 펜스를 걱정할 필요가 없다.

#### 원자성을 보장하는 하드웨어 연산
- 오직 하나의 스레드만 뮤텍스를 붙잡을 수 있으므로 공유 변수에서의 연산은 동시에 실행할 수 없다.
  - 임계 구역이 더 많은 시간을 소비할수록 임계 구역이 동시 실행에서 벗어나는 시간이 더 길어진다.
  - 공유 변수에서 연산하는 스레드가 더 많을 수록 임계 구역이 동시 실행에서 벗어나는 시간이 더 길어진다.
- 스레드가 뮤텍스를 해제하면 대기 중이던 다른 스레드가 뮤텍스를 획득할 수 있다.
  - 뮤텍스는 **어떤 다른 스레드**가 뮤텍스를 획득하는지 보장하지 않는다. (보장하는 데 드는 비용이 크기 때문이다.)
  - 뮤텍스를 획득하기 위해 대기 중인 스레드가 많다면 어떤 스레드는 뮤텍스를 **영원히 획득하지 못할 수도 있다.**
  - 이 스레드에서 수행하는 연산은 앞으로 나아갈 수 없는데 이런 상태를 **기아 상태**라고 한다.
- 스레드가 앞으로 나아갈 수 없는 상황이 발생할 수 있다.
  - 스레드가 첫 번째 뮤텍스를 붙잡고 있는 상태에서 두 번째 뮤텍스가 필요하다.
  - 다른 스레드가 두 번째 뮤텍스를 붙잡고 있는 상태에서 첫 번째 뮤텍스가 필요하다.
  - 이런 상황을 **데드락**이라 부른다.
- 스레드에서 똑같은 뮤텍스에 **락을 두 번** 걸면 스스로 데드락에 빠질 수 있다.
- 스레드 간에 뮤텍스에 대한 **순환 의존 관계**가 생기면 데드락에 빠질 수 있다.
- 여러 뮤텍스를 획득하려는 프로그램에 **교착 회피 전략**이 있다고 하더라도 **데드락 프리**임을 보장할 방법은 없다.
- 하드웨어를 통해 **원자적으로 수행할 수 있는 연산**만 사용해 **스레드 안전 자료구조**를 구현할 수 있다.
  - 이러한 방법으로 작동하는 코드는 뮤텍스를 획득하기 위해 기다릴 필요가 없으므로 **락프리 프로그래밍**이라고 한다.
- 락프리 프로그래밍은 동시 스레드 수를 매우 많이 늘릴 수 있지만 만병통치약은 아니다.
  - 스레드가 수행하는 명령이 한개 뿐이더라도 원자적연산으로 직렬화 된다.

## 12.2 C++ 동시성 기능
### 12.2.1 스레드
- 헤더 파일 `<thread>`는 템플릿 클래스인 `std::thread`를 제공한다.
  - 프로그램은 이 클래스를 통해 스레드 객체를 만들 수 있다.
- `std::thread`의 생성자는 인수로 호출 가능한 객체를 취하고 새로운 소프트웨어 스레드의 콘텍스트에서 실행한다.
- `C++`은 가변 템플릿 인수 포워딩을 사용해 임의의 인수 목록을 갖는 함수를 호출한다.
- `std::thread`는 운영체제 스레드를 관리하는 `RAII` 클래스이다.
  - `std::thread`는 운영체제의 네이티브 스레드 핸들을 반환하는 멤버함수 `get`을 제공한다.

#### std::thread 예제

```cpp
void f1(int n)
{
    std::cout << "thread " << n << std::endl;
}

void thread_example()
{
  std::thread t1;                  // 스레드가 아닌 스레드 변수
  t1 = std::thread(f1, 1);         // 스레드 변수에 스레드 대입
  t1.join();                       // 스레드가 완료될 때까지 기다림 
  std::thread t2(f1, 2);
  std::thread t3(std::move(t2));
  std::thread t4([]() {return; }); // 람다 사용 가능
  t4.detach();
  t3.join();
}
```

- **이동 생성자**가 호출되면 `t3`은 `t2`에서 시작한 스레드를 실행하고 `t2`는 빈스레드가 된다.
- `t4`는 호출 가능한 객체에 람다를 사용할 수도 있다는 것을 보여준다.
- `join()`을 사용할 경우 현재 스레드는 조인된 스레드가 완료될 때까지 기다린다.
- 운영체제 스레드는 `detach` 처럼 `std::thread` 객체와 분리할 수도 있다.
- `std::thread`를 파괴하기 전에 `join()`과 `detach()`를 모두 호출하지 않으면 소멸자가 terminate()를 호출해 프로그램 전체가 중단된다.

### 12.2.2 프로미스와 퓨처
- `std::promise`와 `std::future`는 하나의 스레드에서 다른 스레드로 메시지를 보내고 받는다.
- 프로미스와 퓨처는 값을 **비동기**로 생성하고 예외를 던질 수 있다.
- `std::promise` 템플릿의 인스턴스는 스레드가 지정된 타입의 값이나 예외를 저장하는 공유 상태를 설정할 수 있게 해준다.
  - 값을 보내는 스레드는 값을 받는 스레드가 공유 상태를 읽을때까지 기다리지 않고 즉시 실행을 재개한다.
- 프로미스의 공유 상태는 값이나 예외가 설정될 때까지 준비 상태가 되지 않는다.
- 스레드는 퓨처를 통해 프로미스의 **고유 상태**에 **저장된 값이나 예외**를 받을 수 있다.
  - 스레드는 퓨처에서 결과값을 받을 때까지 실행을 대기할 수 있으므로 퓨처는 **동기화 장치의 역할**을 한다.
- 값을 받는 스레드는 값이나 예외를 설정하는 함수 호출로 해당 프로미스가 준비 상태가 될 때까지 퓨처의 멤버 함수 `get()`의 호출을 보류한다.
- 퓨처는 프로미스로부터 값을 생성하거나 대입 받을 때까지 유효하지 않다.
- 프로미스와 퓨처는 복사할 수 없다.
- 프로미스는 **값을 보내는 스레드**에서 만들어지며 퓨처는 **값을 받는 스레드**에서 만들어진다.
- 퓨처가 준비되면 계산이 완료되었다는 시그널을 보낸다.
  - 프로그램은 퓨처에서 대기할 수 있으므로 스레드 종료 시점에서 대기할 필요는 없다.

#### std::promise, std::future 예제
```cpp
void promise_future_example()
{
    auto meaning = [](std::promise<int>& prom)
    {
        prom.set_value(42);
    };

    std::promise<int> prom;
    std::thread(meaning, std::ref(prom)).detach();

    std::future<int> result = prom.get_future();
    std::cout << "the meaning of life: " << result.get() << "\n";
}
```

- 프로미스 prom은 스레드가 호출되기 전에 생성된다.
- 익명 스레드를 생성한다.
  - 스레드 인수는 호출 가능한 객체인 람다 **meaning**과 **meaning의 인수인 프로미스 prom**이다.
- `detach`를 호출하면 실행 중인 스레드가 파괴된 익명 스레드에서 분리된다.
- 운영체제는 `meaning`을 실행할 준비를 하고 프로그램은 퓨처 `result`를 만든다.
- 프로그램은 스레드가 `prom`의 공유 상태를 설정하기를 기다리며 `result.get()`에서 대기한다.
- 스레드는 `prom.set_value(42)`를 호출해 **공유 상태를 준비 상태**로 만들고 프로그램을 **해제**한다.
- 프로그램은 `the meaning of life: 42`를 출력하고 종료된다.

### 12.2.3 비동기 태스크
- 태스크 템플릿 클래스는 호출 가능한 객체를 `try` 블록으로 감싸고 **프로미스에 반환된 값이나 던져진 예외를 저장**한다.
- 태스크는 스레드에서 호출 가능한 객체를 비동기적으로 호출할 수 있게 한다.
- 호출 가능한 객체를 태스크로 패키징하는 함수 `async()`를 제공하며 재사용 가능한 스레드에서 이 함수를 호출한다.

#### packaged_task 예제
- `std::packaged_task`는 모든 호출 가능한 객체를 감싸서 비동기적으로 호출할 수 있도록 한다.
- `std::packaged_task`는 호출 가능한 객체며 `std::thread`의 인수로 사용할 수 있다.

```cpp
void promise_future_example_2()
{
    auto meaning = std::packaged_task<int(int)>([](int n) {return n; });
    auto result = meaning.get_future();
    auto t = std::thread(std::move(meaning), 42);

    std::cout << "the meaning of life: " << result.get() << "\n";
    t.join();
}
```

- `std::packaged_task` 타입인 `meaning`은 호출 가능한 객체와 `std::promise`를 모두 포함하고 있다.
- 스레드의 콘텍스트에서 호출되는 프로미스의 소멸자를 가져오는 문제를 해결한다.

#### async 예제
- `<async>` 라이브러리는 **태스크를 기반**으로 하는 기능을 제공한다.
- `std::async()`는 인수로 받은 호출 가능한 객체를 실행하고, 호출 가능한 객체는 새 스레드의 콘텍스트에서 실행될 수 있다.

```cpp
void promise_future_example_3()
{
  auto meaning = [](int n) {return n;};
  auto result = std::async(std::move(meaning), 42);
  std::cout << "the meaning of life: " << result.get() << "\n";
}
```
- `meaning`으로 정의된 람다와 람다의 인수는 `std::async()`로 전달된다.
- `async()`의 템플릿 매개변수를 결정하기 위해 **타입 추론**을 사용한다.
- `std::async()`는 `int` 타입의 결과나 예외를 가져갈 수 있는 퓨처를 반환하며 이 값은 `result`로 이동된다.
- `result.get()`을 호출하면 `std::async()`에 의해 호출된 스레드가 `int` 타입의 인수를 반환함으로써 프로미스에 값을 채울때까지 대기한다.
- 스레드 종료는 `std::async()`안에서 관리하는데 이는 스레드 풀에서 스레드를 유지할 수 있다.

### 12.2.4 뮤텍스
#### std::mutex
- 간단하고 효율적인 뮤텍스
- 윈도우에서 우선 바쁜 대기을 시도하고 뮤텍스를 빨리 획득할 수 없을 경우 운영체제 호출로 돌아간다.

#### std::recursive_mutex
- 중첩된 함수 호출처럼 뮤텍스를 이미 가진 스레드가 다시 획득할 수 있게 해주는 뮤텍스이다.
- 이 클래스는 뮤텍스를 획득한 횟수를 세야 하므로 효율성이 떨어질 수 있다.

#### std::recursive_timed_mutex
- `std::mutex`와 `std::recursive_mutex`를 합쳐놓은 뮤텍스이다.
- 다양한 기능을 지원하지만 비용이 크다.

#### std::shared_time_mutex
- 뮤텍스를 획득하기 위해 시도하는 시간을 지정하거나 지정하지 않을 수 있는 공유 뮤텍스이다.

#### std::shared_mutex
- 간단한 공유 뮤텍스
- `C++17`에 추가되었다.

### 12.2.5 락
- 락이라는 단어는 구조화된 방법으로 뮤텍스를 획득하고 해제하는 `RAI` 클래스를 말한다.
- 뮤텍스와 락을 혼동할 수 있는데 아래와 같이 구별하면 된다.
  - 뮤텍스를 획득한다는 것은 뮤텍스에 락을 거는 것이다.
  - 뮤텍스를 해제한다는 것은 뮤텍스에 걸린 락을 푸는 것이다.
- `C++`의 뮤텍스 멤버 함수인 `lock()`을 통해 **뮤텍스를 획득**할 수 있다.

#### std::lock_duard
- 간단한 `RAII` 락이다.
- 프로그램은 클래스를 생성하는 과정에서 락을 획득하기 위해 기다리며 `lock_guard`가 파괴될 때 락을 푼다.
- 이전 표준에서 `scope_guard`라는 이름으로 구현되었다.

#### std::unique_lock
- `RAII` 락, 지연 락, 시간을 지정하는 락, 뮤텍스의 소유권 전달, 조건 변수의 사용을 제공하는 **범용 뮤텍스 소유권 클래스**이다.
- `C++14`에서는 `<shared_mutex>` 헤더 파일에 공유 뮤텍스가 추가되었다.

#### std::shared_lock
- 공유(읽기/쓰기) 뮤텍스를 위한 뮤텍스 소유권 클래스이다.
- `std::unique_lock`의 모든 기능과 공유 뮤텍스의 제어 기능을 제공한다.

### 12.2.6 조건 변수
- 조건 변수는 프로그램이 모니터 개념을 구현할 수 있게 해주며 자바에서는 동기화 클래스라는 개념으로 사용하고 있다.
  - 모니터는 여러 스레드 간에 자료구조를 공유한다.
- 스레드가 성공적으로 모니터에 들어가면 **공유 자료구조**를 갱신할 수 있는 **뮤텍스**를 소유하게 된다.
- 스레드는 공유 자료구조를 갱신한 후 독점 접근을 포기하며 모니터를 떠날 수 있다.
- 특정 변화가 있을 때까지 독점 접근을 일시적으로 포기하며 조건 변수에 대기할 수도 있다.

#### std::condition_variable
- 가장 효율적인 조건 변수
- 뮤텍스에 락을 걸려면 `std::unique_lock`을 사용해야 한다.

#### std::condition_variable_any
- `BasicLockable` 락을 사용할 수 있는 조건 변수
- 멤버 함수 `lock()`과 `unlock()`을 제공하는 모든 락에서 사용할 수 있다.
- `std::condition_variable`보다 효율적이지 않을 수 있다.

#### condition_variable 예제
```cpp
void cv_example()
{
  std::mutex m;
  std::condition_variable cv;
  bool terminate = false;
  int shared_data = 0;
  int counter = 0;

  auto consumer = [&]() {
    std::unique_lock<std::mutex> lk(m);
    do {
      while (!(terminate || shared_data != 0))
      {
         cv.wait(lk);
      }
      if (terminate)
      {
        break;
      }
      std::cout << "consuming " << shared_data << std::endl;
      shared_data = 0;
      cv.notify_one();
    } while (true);
  };

  auto producer = [&]() {
    std::unique_lock<std::mutex> lk(m);
    for (counter = 1; true; ++counter)
    {
      cv.wait(lk, [&]() {return terminate || shared_data == 0; });
      if (terminate)
      {
        break;
      }
      shared_data = counter;
      std::cout << "producing " << shared_data << std::endl;
      cv.notify_one();
    }
  };

  auto p = std::thread(producer);
  auto c = std::thread(consumer);
  std::this_thread::sleep_for(std::chrono::milliseconds(1000));
  {
    std::lock_guard<std::mutex> l(m);
    terminate = true;
  }
  std::cout << "total items produced " << counter << std::endl;
  cv.notify_all();
  p.join();
  c.join();
  exit(0);
}
```
- 생산자는 정수 타입을 갖는 `shared_data`를 0이 아닌 값으로 설정해 생산한다.
- 소비자는 `shared_data`를 0으로 다시 설정해 소비한다.
- 메인 스레드가 깨어나면 뮤텍스`m`에 락을 걸어 모니터에 들어가 `terminate` 플래그를 설정한다.
  - 생산자 소비자 스레드 모두 종료된다.
- 메인 프로그램은 조건 변수에게 종료 상태가 변경되었다고 알리고 두 스레드를 조인한 뒤 종료한다.
- `consumer`는 뮤텍스`m`에 락을 걸어 모니터에 들어간다.
  - 소비자는 조건 변수 `cv`에서 대기하는 반복문이다.
  - 소비자는 `cv`에서 대기하지만 `consumer`는 모니터에 없다.
  - 뮤텍스`m`은 다시 사용가능하고 소비할 무언가가 생기면 `cv`에게 알린다.
  - 소비자가 깨어나고 뮤텍스에 다시 락을 건 뒤 `cv.wait()`로 반환해 개념적으로 모니터에 다시 들어가게 된다.

### 12.2.7 공유 변수에 대한 원자적 연산
- 표준 라이브러리의 헤더 파일 `<atomic>`은 멀티스레드 동기화 장치를 구축하기 위한 저수준 도구들을 제공한다.
- **메모리 펜스**와 **원자적 적재 및 저장**이다.

#### load()
- `std::atomic<T>`는 멤버 함수 `T load(memory_order)`를 제공한다.
- 이 함수는 원자적으로 T 객체를 `std::atomic<T>`밖으로 복사한다.

#### store()
- `std::atomic<T>`는 멤버 함수 `void store(T, memory_order)`를 제공한다.
- 이 함수는 원자적으로 T 객체를 `std::atomic<T>`안으로 복사한다.

#### is_lock_free()
- 이 타입에 정의된 모든 연산이 읽기/수정/쓰기하는 하나의 기계어처럼 상호 배제를 사용하지 않고 구현된 경우 `true`를 반환한다.

#### 메모리 펜스
- `std::atomic`의 멤버 함수 대부분은 연산 주위에 세울 메모리 펜스를 선택하는 `memory_order`라는 인수를 선택적으로 취한다.
  - 인수 `memory_order`에 값을 지정하지 않았다면 기본 값으로 `memory_order_acq_rel`이 지정된다.
  - 항상 안전한 전체 펜스를 제공하지만 비용이 비쌀 수 있다.
- 메모리 펜스는 **메인 메모리**를 여러 **하드웨어 스레드의 캐시와 동기화**한다.
- 하나의 스레드를 다른 스레드와 동기화하기 위해 두 스레드 모두 메모리 펜스를 실행한다.
- C++에서 사용할 수 있는 메모리 펜스는 아래와 같다.

1. memory_order_acquire
   - 다른 스레드가 수행한 **모든 작업을 획득**한다는 의미로 생각할 수 있다.
   - 다음 적재 연산을 현재 적재 연산이나 이전 적재 연산 앞으로 옮기지 못하게 한다.
   - 현재 프로세서와 메인 메모리 사이에서 진행 중인 저장 연산을 완료하기 위해 기다린다.
   - 기본값으로 지정되는 전체 펜스보다 비용이 저렴할 수 있다.

2. memory_order_release
   - 이 시점에 스레드에서 수행한 **모든 작업을 해제**한다는 의미로 생각할 수 있다.
   - 스레드에서 수행한 이전 적재 연산이나 저장 연산을 현재 저장 연산 앞으로 옮기지 못하게 한다.
   - 이 작동은 형재 스레드에서 진행 중인 저장 연산을 완료하기 위해 기다린다.

3. memory_order_acq_rel
   - 앞에 나온 두 가지 펜스를 결합해 **전체 펜스**를 만든다.

4. memory_order_consume
   - 잠재적으로 더 약하고 빠른 `memory_order_acquire`형태이다.
   - 데이터에 의존하는 다른 연산을 수행하기 전에 현재 적재 연산이 수행되기만 하면 된다.

5. memory_order_reloaxed
   - 모든 연산을 재배열 할 수 있다.

### 12.2.8 미래의 C++ 동시성 기능
#### 협력형 멀티 스레딩
- 둘 이상의 소프트웨어 스레드가 명시적 문장으로 두 스레드 사이에서 실행을 전달하므로 실제로는 한 번에 하나의 스레드만 실행된다.
- **코루틴**은 협력형 멀티스레딩의 한 예이다.
- 각 스레드는 활발하게 실행 중이지 않을 경우 콘텍스트를 유지할 수 있다.
- 한 번에 하나의 스레드만 실행하므로 변수는 공유되지 않는다. 따라서 상호배제는 필요하지 않다.

#### SIMD 명령
- `Single Instruction Multiple Data`의 약자로 **하나의 명령어로 여러 개의 값을 동시에 계산**하는 방법이다.
- `SIMD`를 지원하는 프로세서에서 특정 명령은 레지스터의 벡터에서 작동한다.
- 프로세서는 벡터의 각 레지스터에서 동시에 같은 작동을 수행하므로 스칼라 연산보다 오버헤드를 줄인다.

## 12.3 C++ 프로그램 스레드 최적화
### 12.3.1 std::thread보다는 std::async를 사용하세요
- 성능 관점에서 `std::thread`의 중요한 문제는 **호출할 때마다 새로운 소프트웨어 스레드를 시작**한다는 것이다.
- 스레드를 시작하면 **직접 비용**과 **간접 비용** 모두 필요하므로 비용이 매우 많이 든다.
  - 직접 비용은 스레드를 위한 공간괴 스레드의 스택을 위한 메모리를 할당하고 레지스터 집합을 초기화해 실행할 스레드를 예약하는 비용을 포함한다.
  - 간접 비용은 사용하는 메모리량이 증가하면서 생긴다.
- 동시성 프로그래밍에서 유용한 최적화 기법은 스레드를 사용할 때 새로운 스레드를 만드는 대신 기존 스레드를 다시 사용하는 것이다.
- 스레드는 필요할 때까지 어떤 조건 변수에서 대기하고 해제된 다음 호출 가능한 객체를 실행할 수 있다.
- 스레드를 전환하는 비용은 똑같지만, 스레드를 위한 메모리를 할당하고 운영체제에서 예약하는 것과 같은 다른 비용은 없어지거나 줄어든다.
- 템플릿 함수 `std::async()`는 스레드의 콘텍스트에서 호출 가능한 객체를 실행하지만 구현에서는 스레드를 재사용할 수 있다.
```cpp
std::async(std::launch::async, []() { return;});
```
- `std::async()`는 `std::future`를 반환한다.
  - 예제에서는 이름이 지정되지 않은 임시 `std::future`를 반환한다.
- 소멸자는 퓨처가 준비될 때까지 기다리므로 발생할 가능성이 있는 모든 예외를 던질 수 있다.
- `join()`이나 `detach()`를 명시적으로 호출할 필요가 없다.

### 12.3.2 실행 가능한 스레드를 코어 수만큼 많이 만드세요
- 최적화 담당 개발자는 두 가지 종류의 스레드를 서로 다른 작동으로 구분할 수 있다.

#### 실행 가능한 스레드는 끊임없이 계산합니다
- 실행 가능한 스레드는 실행 중인 코어의 컴퓨팅 자원을 `100%` 소비한다.
- 코어가 `n`개라면 각 코어에 실행 가능한 스레드를 스케줄링했을 때 전체 실행 시간을 `1/n` 까지 줄일 수 있다.
- 사용 가능한 각 코어에서 스레드를 실행하고 나면 추가 스레드를 스케줄링 했을 때 실행 시간이 더는 개선되지 않는다.
- 스레드는 사용할 수 있는 하드웨어 파이 조각을 잘게 자른다.
- 실행 가능한 스레드 수가 증가하면 성능이 전반적으로 떨어져 궁극적으로는 0에 가까워질 수 있다.

#### 대기 가능한 스레드는 외부 이벤트를 기다린 후 잠시 계산합니다
- 대기 가능한 스레드는 코어에서 사용 가능한 계산 자원 중 몇 %만 소비한다.
- 하나의 코어에서 대기 가능한 여러 스레드를 스케줄링하면 사용 가능한 자원의 상당 부분을 차지한다.
  - 대기 가능한 스레드의 실행이 서로 교차되면 다른 스레드를 기다리는 동안 또 다른 스레드 하나에서 계산이 진행될 수 있기 때문이다.
- 전체 실행 시간을 모든 계산 자원을 사용하는 포화점까지 줄일 수 있다.
- `std::thread::hardware_concurrency()`를 사용하여 사용 가능한 코어수를 획득할 수 있다.

### 12.3.3 태스크 큐와 스레드 풀 구현하기
- 실행 중인 스레드의 수를 알 수 없는 문제는 **스레딩을 명시적**으로 만들어 해결할 수 있다.
- 수명이 긴 스레드를 포함하는 자료구조인 **스레드 풀**과 수행할 계산 목록을 포함하는 자료구조인 **태스크 큐**를 제공하는 것을 말한다.
- **태스크지향 프로그래밍**에서 프로그램은 실행 가능한 태스크 객체의 모임으로 작성된다.
  - 태스크 객체는 **스레드 풀에 있는 스레드**를 통해 실행된다.
  - 스레드를 사용할 수 있게 되면 태스크 큐에서 태스크를 가져온다.
  - 스레드가 태스크를 끝냈을 때 스레드는 종료되지 않으며 실행할 새 태스크가 도착할 때까지 대기하며 다음 태스크 또는 블록을 실행한다.
- 태스크지향 프로그램의 장점
  - 논블로킹 `I/O` 호출로부터 `I/O` 완료 이벤트를 효율적으로 처리해 **프로세서 활용률**을 높일 수 있다.
  - 스레드 풀과 태스크 큐를 사용하며 수명이 짧은 태스크를 수행하는 **스레드를 시작할 때 발생하는 오버헤드를 제거**할 수 있다.
  - 비동기 처리를 하나의 자료구조 집합으로 중앙 집중화해 **사용 중인 스레드 수를 쉽게 제한**할 수 있다.
- 태스크지향 프로그램의 단점
  - **제어 반전 문제**가 존재한다.
  - 제어 반전은 제어 흐름이 프로그램에서 지정되는 대신, 이벤트 메시지가 수신된 순서대로 포함된다.
  - 디버깅 하기 어려울 수 있다.

### 12.3.4 별도의 스레드에서 I/O 수행하기
- 회전하는 디스크와 원거리 네트워크 연결이 갖는 현실은 프로그램이 데이터를 요청하는 시간과 사용할 수 있는 시간사이에 지연을 일으킨다.
- `I/O`는 **동시성**을 찾을 수 있는 완벽한 장소이다.
- 프로그램에서 데이터를 쓰기 전이나 읽은 후에 변환해야 하는 것 또한 `I/O`이다.
  - `XML` 파일을 예로 들면 인터넷에서 데이터를 읽은 후 파싱해 정보를 추출한다.
- 데이터를 변환하기 전에는 사용할 수 없기 때문에 읽기나 파싱을 포함한 모든 과정은 별도의 스레드로 옮길 수 있는 후보가 된다.

### 12.3.5 동기화 없는 프로그램
- **동기화**와 **상호 배제**는 멀티스레드 프로그램을 느리게 만든다.
- 동기화를 없앤다면 성능을 향상할 수 있다.

#### 이벤트지향 프로그래밍
- 프로그램은 프레임워크에서 호출되는 **이벤트 처리 함수의 모음**으로 작성된다.
- 기본 프레임워크는 각 이벤트를 이벤트 큐에서 해당 이벤트에 등록된 **핸들러 함수**로 보낸다.
- 이벤트 지향 프로그래은 **태스크 지향 프로그래밍**과 비슷한 점이 많다.
- 프레임워크는 **싱글 스레드**이며 이벤트 핸들러 함수는 동시에 실행되지 않는다.
- 이벤트지향 프로그램의 장점
  - 기본 프레임워크는 싱글스레드이므로 동기화할 필요가 없다.
  - 논블로킹 `I/O` 호출로부터 `I/O` 완료 이벤트를 효율적으로 처리할 수 있다.
- 이벤트지향 프로그램의 단점
  - 태스크지향 프로그램과 마찬가지로 **제어 반전** 문제가 있다.
  - 제어 반전은 제어 흐름이 프로그램에서 지정되는 대신, 이벤트 메시지가 수신된 순서대로 포함된다.
  - 디버깅 하기 어려울 수 있다.

#### 코루틴
- 실행을 명시적으로 하나의 객체에서 다른 객체로 넘기는 **실행 가능한 객체**이다.
- 다시 호출할 경우 재개할 수 있도록 코루틴의 실행 포인터를 기억한다.
- 이벤트지향 프로그램과 마찬가지로 진짜 멀티스레드가 아니므로 여러 스레드에서 제어하지 않는 한 동기화할 필요가 없다.
- 두 가지 종류가 있다.
  - **자체 스택**을 가지며 실행 지점에 상관없이 제어권을 다른 코루틴에게 넘길 수 있다.
  - **다른 스레드의 스택**을 빌리며 최상위 레벨에서만 제어권을 넘길 수 있다.

#### 메시지 전달
- 제어의 흐름은 하나 이상의 소스에서 입력을 받아 변환한 뒤 하나 이상의 출력 싱크에 놓는다.
  - 연결된 출력과 입력은 잘 정의된 진입 및 진출 노드가 있는 그래프를 형성한다.
  - 각 단계를 구현하는 스레드로 읽고 쓰는 항목들은 네트워크 데이터그램, 문자 `I/O` 스트림, 명시적인 큐의 자료구조로 구현될 수 있다.
- 예로 유닉스의 명령줄 파이프라인과 웹 서비스가 있다.
- 메시지 전달 프로그램의 장점
  - 각 단계의 **출력**과 다음 단계의 **입력**은 서로 **묵시적인 동기화**를 한다.
  - 한 단계의 출력은 각각 다음 단계의 단일 입력과 연결되어 있으므로 **기아 상태와 공정성 문제**의 발생 빈도가 줄어든다.
  - 동기화는 데이터 단위가 클수록 발생 빈도가 줄어든다. 여러 스레드가 동시에 실행될 수 있는 시간의 비율을 증가시킬 수 있다.
  - 파이프라인 단계는 변수를 공유하지 않아서 **뮤텍스**와 **메모리 펜스** 때문에 속도가 느려지지 않는다.
  - 파이프라인 단계 사이에 더 큰 작업 단위를 전달해 각 단계가 상호 배제를 위해 멈추거나 시작하지 않고 타임 슬라이스 전체를 사용할 수 있다.
- 메시지 전달 프로그램의 단점
  - 메시지는 본질적으로 객체지향적이지 않다.
  - 입력 메시지를 멤버 함수 호출로 마샬링(메모리에 저장된 데이터를 전송 혹은 다른 매체에 저장 가능한 형태로 변환하는 것)하는 코드를 작성해야 한다.
  - 파이프라인 단계에서 오류가 발생할 때 **오류 복구**가 문제가 될 수 있다.
  - 모든 문제가 메시지를 전달하는 독립 프로그램의 파이프라인으로 명백한 해결책이 있지는 않다.

#### 락프리 프로그래밍
- **상호 배제 없이 멀티스레딩으로 자료구조를 갱신**할 수 있게 해주는 프로그래밍 방법을 말한다.
- 비용이 큰 뮤텍스는 하드웨어로 동기화되는 원자적 연산으로 대체된다.
- 락프리 자료구조는 뮤텍스로 보호를 받는 기존 컨테이너보다 더 나은 성능을 발휘할 수 있다.
- 락프리 자료구조는 추론하기 매우 어렵기 때문에 직접 구축하기보다는 공개된 코드를 사용하는것이 좋다.

### 12.3.6 시작 및 종료 코드 제거하기
- 프로그램은 작업을 동시에 수행하거나 `CPU`코어를 여러개 사용하기 위해 스레드를 필요한 만큼 실행할 수 있다.
- **main()이 제어권을 얻기 전**과 **main()이 종료된 후 실행되는 코드**는 동시에 실행하기 매우 어렵다.
- `main()`이 시작되기 전에 **정적 저장 기간**을 갖는 모든 변수가 초기화된다.
  - 이때 `POD` 자료형(`plain old data`)은 초기화하는 데 비용이 들지 않는다.
  - 링커는 변수들이 초기화 데이터를 가리키도록 연결한다.
- 클래스 타입 변수와 정적 저장 기간을 갖는 변수들은 싱글스레드에서 표준에서 정의된 특정 순서대로 각 변수의 생성자를 호출해 초기화한다.

## 12.4 더 효율적인 동기화 만들기
- 동기화는 공유 메모리 동시성의 **오버헤드 비용**이다.
- 성능을 최적화하려면 오버헤드 비용을 줄이는 것이 매우 중요하다.
- 뮤텍스와 같은 동기화 장치는 비용이 크다.
- 경쟁 상태가 심하지 않다면 뮤텍스를 붙잡더라도 다른 스레드의 속도가 느려지지 않는다.

### 12.4.1 임계 구역의 범위 줄이기
- 임계 구역은 **뮤텍스를 획득하고 해제하는 코드로 둘러싸인 코드 영역**이다.
- 실행하는 동안 다른 스레드는 해당 뮤텍스로 제어되는 공유 변수에 접근할 수 없다.
- 공유 변수에 접근하는 것 **외에는** 아무것도 하지 않으므로 다른 스레드는 아무 이유없이 기다려야 한다.
- 조건 변수를 기다리는 동안을 제외하고 코드가 모니터에 항상 있는 모니터 개념은 효율적으로 사용하기 어려울 수 있다.
- 임계 구역에서 **I/O를 수행**하면 최적의 성능을 이끌어내지 못한다.

### 12.4.2 동시 스레드 수 제한하기
- 12.3.2절 처럼 콘텍스트 스위칭의 오버헤드를 제거하기 위해 **실행 가능한 스레드 수는 프로세서 코어 수보다 작거나 같야아 한다.**
- 스레드 수가 코어 수보다 많으면 스레드 중 일부만 코어에 할당되고 어느 순간에 진행한다.
  - 나머지 스레드는 운영체제의 실행 가능한 큐에서 대기하며 시간 할당을 받게 된다.
- 임계 구역을 짧게 만들기 위해 경쟁하는 스레드의 **이상적인 개수는 2개**이다.
- 스레드 수가 2개면 기아 상태와 공정성 문제가 없으며 놀란 양떼 문제가 생길 가능성도 없다.

### 12.4.3 놀란 양 떼 피하기
- 놀란 양 떼 현상은 **하나의 스레드**만 서비스 할 수 있는 이벤트에서 **많은 스레드가 대기 중**일때 발생하는 현상이다.
- 이벤트가 발생하면 모든 스레드를 실행할 수 있게 되지만 코어가 적어서 즉시 실행할 수 있는 스레드는 몇개 뿐이다.
  - 이 중 하나를 작업 항목으로 가져온다.
  - 운영체제는 나머지 스레드를 실행 가능한 큐로 옮기고 하나씩 실행한다.
- 각 스레드는 시그널을 보낸 이벤트가 이미 서비스되었다는 사실을 알게 되고 그 이벤트에서 다시 **대기**하며 진척을 이루지 못한 채 시간을 보낸다.

### 12.4.4 락 전달 피하기
- 락 전달은 많은 스레드가 자원이나 임계 구역에서 보류하면서 동기화 할때 발생한다.
  - 스레드들은 하나씩 진행하도록 만들어졌는데 모두 한번에 진행하려고 하기 때문에 혼잡을 야기한다.
- 단순한 경우 놀란 양 떼 현상이 계속해서 발생한다.
- 뮤텍스를 위해 경쟁하는 스레드는 충분하고 많은 스레드가 뮤텍스의 운영체제 시그널에서 대기한다.
- 뮤텍스를 붙잡고 있는 스레드가 이를 해제하면 이벤트를 감지하고 보류중인 **모든 스레드는 실행 가능한 상태**가 된다.
  - 프로세서를 얻는 **첫 번째 스레드는 뮤텍스에 락**을 건다.
  - 나머지 스레드는 프로세서를 가져와서 뮤텍스를 검사해 여전히 락이 걸려있다는 사실을 확인하고 **대기 상태**로 돌아간다.
- 운영체제가 스레드를 다시 시작하는 데 많은 시간을 소비하지만 대부분의 스레드는 진행되지 않는다.
  - 모든 스레드는 여전히 동기화 되어있다.
  - 다음 스레드가 뮤텍스를 해제하고 나면 모든 스레드가 깨어나도 이 사이클을 반복하게 된다.
- 더 복잡한 경우에 스레드의 놀란 양 떼 현상은 두 번째 뮤텍스를 획득하려 하거나 장치의 물리적 특성 때문에 발생하는 병목 현상이 있는 파일의 읽기 등의 작동을 수행하려고 한다.
  - 스레드는 동기화되기 때문에 모두 동시에 두 번쨰 자원에 접근하려고 하고 동시에 같은 자원을 요청했기에 성능이 저하된다.
  - 스레드가 동기화되지 않았다면 모두 진행되었을 것이다.
- 락 전달은 잘 작동하는 시스템으로 볼 수 있지만 때때로 한 번에 몇 초동안 응답하지 않는 것처럼 보인다.
- **스레드 수를 줄이거나** 스레드가 **서로 다른 시간에 시작하도록 스케줄링** 하면 락 전달 문제를 줄일 수 있다.
  - 다른 장소에서 락 전달 문제가 발생할 위험이 항상 있다.
- 특정 태스크 그룹이 하드웨어 장치나 다른 병목 현상을 공유하기 때문에 **동시에 수행할 수 없다는 점을 인정**하는 것이 최선의 방법이다.

### 12.4.5 경쟁 상태 줄이기
- 멀티스레드 프로그램에서 스레드는 자원을 두고 경쟁할 수 있다.
- **둘 이상의 스레드가 같은 자원**을 필요로 하게 되면 **임계 구역**이 생기고 스레드는 **대기 상태**가 되어 동시성을 잃는다.
- 아래는 경쟁 상태 문제를 해결할 수 있는 기법들이다.

#### 메모리와 I/O가 자원이라는 점을 인지하세요
- 메모리 관리자도 자원이다.
- 메모리 관리자는 멀티 스레드 시스템에서 접근을 **직렬화** 해야 한다.
- 동적 변수들을 한꺼번에 할당하려는 다수의 스레드는 스레드 수가 증가함에 따라 **성능이 급격하게 떨어진다.**
- 파일`I/O`도 자원이다.
  - 디스크 드라이브의 판독 헤드는 한 번에 한 곳에만 있을 수 있다.
  - 여러 파일에 동시에 `I/O`를 시도하면 **성능이 저하**될 수 있다.
- 네트워크 `I/O`도 자원이다.
  - 이더넷 커넥터는 비트를 내뿜는 좁은 파이프이다.
  - 현대의 프로세서는 기가비트 인터넷 케이블조차 포화시킬 수 있다.
  - 와이파이 연결은 손쉽게 포화시킬 수 있다.

#### 복제 자원
- 여러 스레드가 공유 맵이나 해시 테이블과 같은 자원을 경쟁하는 대신 **테이블을 복제**해 각 스레드가 공유되지 않은 복사본을 갖게 하면 경합 문제를 없앨 수 있다.
- 자료구조 복사본을 2개 유지해야 하기 때문에 작업이 더 많지만 공유 자료구조보다 전체 실행 시간이 줄어들 수 있다.
- 디스크 드라이브와 네트워크 인터페이스 카드와 같은 **하드웨어 자원도 복제**해 처리량을 높일 수 있다.

#### 분할 자원
- 여러 스레드가 하나의 자료구조를 위해 경쟁하는 대신 자료구조를 분할해 각 스레드가 작업할 일부 데이터에만 접근할 수 있도록 만들 수 있다.

#### 미세한 락 걸기
- 하나의 뮤텍스로 자료구조 전체에 락을 거는 대신 **여러 뮤텍스**를 사용해 락을 걸 수 있다.

#### 락프리 자료구조
- 해시 테이블과 같은 락프리 자료구조를 사용하면 상호배제의 필요성을 줄일 수 있다.
- 미세한 락걸기를 사용할 수 있는 궁극적 범위이다.

#### 자원 스케줄링
- 하드 드라이브처럼 일부 자원은 복제나 분할에 영향을 받지 않는다.
- 디스크 활동을 스케줄링해서 모든 작동이 한꺼번에 발생하지 않게 하거나 디스크의 인접 부분에 접근하는 작동을 함께 수행하도록 만들 수 있다.
- 운영체제는 읽기와 쓰기를 미세한 수준으로 스케줄링 할 수 있다.
- 프로그램은 모든 작동이 동시에 발생하지 않도록 구성 파일 읽기와 같은 작업의 순서를 정할 수 있다.

### 12.4.6 싱글 코어 시스템에서 바쁜 대기를 하지 마세요
- 개발자는 `C++` 동시성 기능을 통해 바쁜 대기를 하는 고성능 동기화 장치를 구현할 수 있다.
  - 바쁜 대기가 항상 좋지는 않다.
- 싱글 코어 프로세서에서 스레드를 동기화하는 유일한 방법은 운영체제의 **동기화 장치를 호출**하는 것이다.
  - 바쁜 대기는 효과가 없다.
- 바쁜 대기는 스레드에 할당된 **시간을 낭비**하게 만든다.
  - 뮤텍스를 붙잡고 있는 스레드는 대기 중인 스레드가 프로세서를 포기할 때까지 실행할 수 없어서 임계 구역을 완료할 수 없기 때문이다.

### 12.4.7 영원히 대기하기 마세요
- 무조건 이벤트를 대기하는 스레드는 프로그램이 정상적으로 실행된다면 아무일도 일어나지 않는다.
- 사용자가 프로그램을 멈추려고 하면 사용자 인터페이스는 종료되지만 **여전히 실행 중인 스레드**가 있기 때문에 프로그램은 멈추지 않는다.
  -` main()`이 대기중인 스레드에 조인하려고 하면 행이 걸린다.
- 대기 중인 스레드가 분리되면 `main()`이 종료된다.
  - 그 다음에는 스레드가 어떻게 대기하는가에 따라 달라진다.
  - 플래그가 설정되기를 기다리고 있다면 영원히 대기한다.
  - 운영체제 이벤트에서 기다리고 있다면 영원히 대기한다.
    - C++ 객체에서 기다리고 있다면 일부 논블로킹된 스레드가 객체를 삭제하는지에 따라 달라진다.
- 영원히 대기하는 것은 오류 복구의 적이다.

### 12.4.8 사용자 정의 뮤텍스 사용은 효과적이지 않을 수 있습니다
- 다른 스레드가 원자적 변수를 갱신할 때까지 바쁜 대기 상태인 뮤텍스 역할을 하는 단순 클래스 코드를 작성하는 것은 어렵지 않다.
  - 이런 클래스는 경쟁 상태가 약하고 임계 구역이 짧다면 시스템이 제공하는 뮤텍스보다 빠를 수 있다.
- 운영체제와 함께 제공되는 뮤텍스는 운영체제에 대한 비밀과 성능 개선, 특정 운영체제에서 우선순위 역전 문제를 피하는 태스크를 스케줄링 하는 방법을 안다.
- 강력한 뮤텍스의 설계는 반드시 실행해야 하는 운영체제의 설계에서 영향을 받는다.
  - **사용자 정의 뮤텍스**를 사용하는 것은 최적화로 가는 길이 아니다.

### 12.4.9 생산자 출력 큐의 길이 제한하기
- 생산자/소비자 프로그램에서 생산자의 처리 속도가 소비자의 처리속도보다 빠를 때마다 생산자와 소비자 사이의 **큐에 데이터를 축적**한다.
- 생산자는 프로세서, 메모리 할당자, 다른 자원을 위해 경쟁한다. 게다가 소비자를 느리게 만들고 문제를 악화한다.
- 생산자는 모든 시스템 메모리 자원을 소비해 프로그램 전체가 갑자기 종료되도록 야기할 수 있다.
- 프로그램이 예외에서 복구되도록 설계되었다면 프로그램을 다시 시작하기 전에 대기 중인 모든 데이터를 처리해야 하므로 복구 시간이 길어진다.
- 해결책은 **큐의 크기를 제한**하고 **큐가 가득 차면 생산자를 막는 것**이다.